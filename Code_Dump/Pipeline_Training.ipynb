{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d87766f",
   "metadata": {},
   "source": [
    "### Importing Libraries and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6e2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "# Taking pipeline building configurations from config.json.\n",
    "# These are only for building and will not be available at \n",
    "# the runtime of the pipeline.\n",
    "with open(\"config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7950b",
   "metadata": {},
   "source": [
    "### Setting Default Bucket for the Pipeline and getting region and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397572bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\n",
      "<sagemaker.session.Session object at 0x7f5f180d8240>\n",
      "<bound method Session.default_bucket of <sagemaker.session.Session object at 0x7f5f180d8240>>\n"
     ]
    }
   ],
   "source": [
    "# Setting default bucket\n",
    "sagemaker_session = sagemaker.session.Session(default_bucket = build_parameters[\"output_bucket\"])\n",
    "\n",
    "# Getting region and role\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)\n",
    "print(sagemaker_session)\n",
    "print(sagemaker_session.default_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe242b4",
   "metadata": {},
   "source": [
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148feb3",
   "metadata": {},
   "source": [
    "#### Input Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2f50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Default location for the datasets\n",
    "train_data_uri = build_parameters[\"train_data\"]\n",
    "test_data_uri = build_parameters[\"test_data\"]\n",
    "evaluation_data_uri = build_parameters[\"evaluation_data\"]\n",
    "feature_selection_file_uri = build_parameters[\"feature_selection\"]\n",
    "\n",
    "\n",
    "# Parametrizing Data paths\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "train_data = ParameterString(name=\"TrainData\", default_value = train_data_uri)\n",
    "test_data = ParameterString(name=\"TestData\", default_value = test_data_uri)\n",
    "evaluation_data = ParameterString(name=\"EvaluationData\", default_value = evaluation_data_uri)\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = feature_selection_file_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ab54a",
   "metadata": {},
   "source": [
    "#### Input Model Locations (If Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1f3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_given = ParameterString(name=\"ModelGiven\", default_value = \"No\")\n",
    "model_s3_path = ParameterString(name=\"ModelPath\", default_value = \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02983288",
   "metadata": {},
   "source": [
    "### Machine types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889bd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing machine type\n",
    "local_preprocessing_path = os.path.join(\"Pipeline_Component_Codes\",\"Training\",\"1_Preprocessing\")\n",
    "with open(os.path.join(local_preprocessing_path, \"config.json\")) as file:\n",
    "    processing_build_parameters = json.load(file)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=processing_build_parameters[\"machine_type\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Modeling machine types\n",
    "local_models_path = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"2_Models_HPTune\")\n",
    "models = [dir if '.' not in dir for dir in os.listdir(local_models_path)]\n",
    "model_details = []\n",
    "for i in range(len(models)):\n",
    "    name = models[i]\n",
    "    with open(os.path.join(local_models_path, name, \"config.json\")) as file:\n",
    "        build_parameters = json.load(file)\n",
    "    model_details.append({\"name\":name, \"build_parameters\":build_parameters})\n",
    "\n",
    "for i in range(len(model_details)):\n",
    "    training_instance_type = ParameterString(\n",
    "        name=f\"{model_details[i]['name']}InstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b23eb",
   "metadata": {},
   "source": [
    "### Handling output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd12d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling the output location\n",
    "# Default output location\n",
    "# pipeline_s3_output_bucket = f\"{usecase}-output-bucket-{region}\" \n",
    "# pipeline_s3_output_bucket = build_parameters[\"output_bucket\"]\n",
    "pipeline_output_bucket = build_parameters[\"output_bucket\"] \n",
    "\n",
    "# Making the output location runtime parameter\n",
    "# pipeline_output_bucket = ParameterString(name = \"PipelineOutputBucket\", default_value = pipeline_s3_output_bucket) \n",
    "sagemaker_session.default_bucket = pipeline_output_bucket\n",
    "\n",
    "# Creating the output bucket if it is not already present\n",
    "s3 = boto3.client('s3')\n",
    "buckets = [dictionary[\"Name\"] for dictionary in s3.list_buckets()['Buckets']]\n",
    "if pipeline_output_bucket not in buckets:\n",
    "    location = {'LocationConstraint': region}\n",
    "    response = s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration = location)\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "pipeline_start_time = strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "from sagemaker.workflow import functions\n",
    "\n",
    "# These variables were written thinking that output path can be taken as parameter, yes it can be done,\n",
    "# but not all the pipeline steps accepts pipeline parameter as input, so we had to pick the output path from config\n",
    "# file instead of as parameter\n",
    "# processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"ProcessingOutput\"])\n",
    "# evaluation_processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"EvaluationProcessingOutput\"])\n",
    "# # hptune_training_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"HPTuneTrainingOutput\"])\n",
    "# hptune_training_output_path = f\"s3://{pipeline_s3_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/HPTuneTrainingOutput\"\n",
    "# evaluation_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"EvaluationOutput\"])\n",
    "\n",
    "\n",
    "processing_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/ProcessingOutput\"\n",
    "evaluation_processing_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/EvaluationProcessingOutput\"\n",
    "# hptune_training_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"HPTuneTrainingOutput\"])\n",
    "hptune_training_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/HPTuneTrainingOutput\"\n",
    "evaluation_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/EvaluationOutput\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41278e90",
   "metadata": {},
   "source": [
    "### Preprocessing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da649f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.1 Loading preprocessing config.json file.\n",
    "local_preprocessing_path = os.path.join(\"Pipeline_Component_Codes\",\"Training\",\"1_Preprocessing\")\n",
    "with open(os.path.join(local_preprocessing_path, \"config.json\")) as file:\n",
    "    processing_build_parameters = json.load(file)\n",
    "\n",
    "    \n",
    "# 2.2 Making parameter for processing machine type\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=processing_build_parameters[\"machine_type\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44592802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'processing_type': 'sklearn_processing',\n",
       " 'framework_version': '0.23-1',\n",
       " 'entry_point': 'Training_Preprocessing.py',\n",
       " 'dependencies': 'requirements.txt',\n",
       " 'machine_type': 'ml.m4.xlarge',\n",
       " 'machine_count': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_build_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b9cbb",
   "metadata": {},
   "source": [
    "#### 2.3 Building the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9462106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if processing_build_parameters[\"processing_type\"] == \"sklearn\":\n",
    "    from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "    processor = SKLearnProcessor(\n",
    "        framework_version = processing_build_parameters[\"framework_version\"],\n",
    "        instance_type = processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )\n",
    "elif processing_build_parameters[\"processing_type\"] == \"custom\":\n",
    "    from sagemaker.processor import Processor\n",
    "    processor = Processor(\n",
    "        image_uri = processing_build_parameters[\"image_uri\"],\n",
    "        instance_type = processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e23897",
   "metadata": {},
   "source": [
    "#### 2.4 Building preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab9a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name = \"preprocessing_full_data\",\n",
    "    description = \"Data preprocessing and splitting into train and test set\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source = train_data, destination=\"/opt/ml/processing/input/data\"),  \n",
    "        ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        # Train\n",
    "        ProcessingOutput(output_name = \"train\", source=\"/opt/ml/processing/train\", \n",
    "#                          destination = sagemaker.workflow.functions.Join(on='/', values = [processing_output_path, \"data\"])\n",
    "                        ),\n",
    "        # Test\n",
    "        ProcessingOutput(output_name = \"test\", source=\"/opt/ml/processing/test\", \n",
    "#                          destination = sagemaker.workflow.functions.Join(on='/', values = [processing_output_path, \"data\"])\n",
    "                        ),\n",
    "        # Logs\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "#                          destination = sagemaker.workflow.functions.Join(on='/', values = [processing_output_path, \"logs\"])\n",
    "                        ),\n",
    "    ],\n",
    "#     code=\"SageMaker_Pipeline_Component_Codes/Training/Training_Preprocessing.py\",\n",
    "    code=os.path.join(local_preprocessing_path, processing_build_parameters[\"entry_point\"]),\n",
    "    job_arguments = [\"--train_data_location\", \"/opt/ml/processing/input/data\", \n",
    "                     \"--feature_selection_file_location\", \"/opt/ml/processing/input/feature_selection\", \n",
    "                     \"--target_column\", \"Churn\",\n",
    "                     \"--preprocessed_train_data_location\", \"/opt/ml/processing/train\", \n",
    "                     \"--preprocessed_test_data_location\", \"/opt/ml/processing/test\", \n",
    "                     \"--log_location\", \"/opt/ml/processing/logss\"\n",
    "                    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d641e",
   "metadata": {},
   "source": [
    "### Preprocessing Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554e0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor_evaluation = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=build_parameters[\"processing_instance_type\"],\n",
    "    instance_count=build_parameters[\"processing_instance_count\"],\n",
    "    base_job_name=f\"{usecase}-preprocessing-validation\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "step_process_evaluation = ProcessingStep(\n",
    "    name=\"preprocessing_validation_data\",\n",
    "    # processor=sklearn_processor_evaluation,\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=evaluation_data, destination=\"/opt/ml/processing/input/data\"), \n",
    "        ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = sagemaker.workflow.functions.Join(on='/', values = [evaluation_processing_output_path, \"data\"])),\n",
    "        ProcessingOutput(output_name=\"logs\", source=\"/opt/ml/processing/logss\", destination = sagemaker.workflow.functions.Join(on='/', values = [evaluation_processing_output_path, \"logs\"]))\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Training/Training_Preprocessing.py\",\n",
    "    code = f\"s3://{pipeline_input_bucket}/codes/{build_parameters['processing_code_file_name']}\",\n",
    "    depends_on = [step_process],\n",
    "    job_arguments = [\"--train_data_location\", \"/opt/ml/processing/input/data\", \"--feature_selection_file_location\", \n",
    "                     \"/opt/ml/processing/input/feature_selection\", \"--target_column\", \"Churn\", \"--stop_split\", \"Y\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3812b80",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69e18f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_objective_metric_name = build_parameters[\"objective_metric\"]\n",
    "objective_metric_name = ParameterString(name = \"ObjectiveMetric\", default_value = default_objective_metric_name)\n",
    "metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"accuracy:([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2d5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "sklearn_image_uri = image_uris.retrieve(framework='sklearn', region=region, version='0.23-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a2c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter, HyperparameterTuner, WarmStartConfig, WarmStartTypes\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "duplicate_objective_metric_name = ParameterString(name = \"ObjectiveMetric\", default_value = default_objective_metric_name)\n",
    "\n",
    "n_models = build_parameters[\"number_of_models\"]\n",
    "tuning_steps = []\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    if model_details[\"model_type\"] == 'sklearn_model':\n",
    "        estimator = SKLearn(source_dir = f\"s3://{pipeline_input_bucket}/codes/{model_details['model_name']}.tar.gz\", \n",
    "                            entry_point = model_details[\"entry_point\"], \n",
    "                            dependencies = model_details[\"dependencies\"], \n",
    "                            instance_type = model_details[\"instance_type\"], \n",
    "                            framework_version = '0.20.0', \n",
    "                            output_path = f\"{hptune_training_output_path}/{model_details['model_name']}\",\n",
    "                            image_uri = sklearn_image_uri, role = role\n",
    "                            )\n",
    "        \n",
    "        hyperparameters = model_details[\"hyperparameters\"].keys()\n",
    "        hyperparameter_ranges = {}\n",
    "        for hyperparameter in hyperparameters:\n",
    "            if model_details[\"hyperparameters\"][hyperparameter][\"type\"] == \"categorical\":\n",
    "                hyperparameter_ranges[hyperparameter] = CategoricalParameter(model_details[\"hyperparameters\"][hyperparameter][\"values\"])\n",
    "            elif model_details[\"hyperparameters\"][hyperparameter][\"type\"] == \"integer\":\n",
    "                hyperparameter_ranges[hyperparameter] = IntegerParameter(min_value = model_details[\"hyperparameters\"][hyperparameter][\"min_value\"],\n",
    "                                                                         max_value = model_details[\"hyperparameters\"][hyperparameter][\"max_value\"])\n",
    "        \n",
    "        hyperparameter_ranges[\"objective_metric\"] = CategoricalParameter([objective_metric_name, \"anything\"])\n",
    "        tuner = HyperparameterTuner(\n",
    "            estimator,\n",
    "            objective_metric_name,\n",
    "            hyperparameter_ranges,\n",
    "            metric_definitions,\n",
    "            max_jobs=1,\n",
    "            max_parallel_jobs=1,\n",
    "            strategy = model_details[\"tuning_strategy\"],\n",
    "            base_tuning_job_name = model_details[\"model_name\"],\n",
    "            # base_tuning_job_name=f\"Decision_Tree_{strftime('%Y%m%d-%H-%M-%S', gmtime())}\"\n",
    "            )\n",
    "        # print(f\"HPTuning-{model_details['model_name']}\")\n",
    "        step_tuning = TuningStep(\n",
    "            name = f\"hptuning-{model_details['model_name']}\",\n",
    "            tuner = tuner,\n",
    "            inputs={\n",
    "                \"train\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"test\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        tuning_steps.append(step_tuning)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92412b0",
   "metadata": {},
   "source": [
    "### Getting the best model from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56d4aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=build_parameters[\"evaluation_instance_type\"],\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "create_best_model_steps = []\n",
    "entry_point='SageMaker_Pipeline_Component_Codes/Training/Evaluation.py',\n",
    "for i in range(n_models):\n",
    "    tuning_step_best_model = Model(image_uri = tuning_steps[i].tuner.estimator.image_uri, \n",
    "                                   source_dir = f\"s3://{pipeline_input_bucket}/codes/evaluation.tar.gz\",\n",
    "                                   # source_dir = build_parameters[\"single_model_evluation_source_dir\"],\n",
    "                                   entry_point = build_parameters[\"single_model_evluation_entry_point\"],\n",
    "                                   model_data = sagemaker.workflow.functions.Join(on='/', values=[hptune_training_output_path, tuning_steps[i].name[9:], tuning_steps[i].properties.BestTrainingJob.TrainingJobName, \"output/model.tar.gz\"]), \n",
    "                                   role = role,\n",
    "                                   sagemaker_session = sagemaker_session\n",
    "                                  )\n",
    "    \n",
    "    step_create_best_model = CreateModelStep(\n",
    "        name = f\"Getting-Best-{tuning_steps[i].name[9:]}-Model\",\n",
    "        model = tuning_step_best_model,\n",
    "        inputs = inputs\n",
    "    )\n",
    "    \n",
    "    create_best_model_steps.append(step_create_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02825963",
   "metadata": {},
   "source": [
    "### Evaluating the best models from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6984dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_steps = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    transformer_dt = Transformer(\n",
    "        model_name = create_best_model_steps[i].properties.ModelName,\n",
    "        instance_type = build_parameters[\"evaluation_instance_type\"],\n",
    "        instance_count=1,\n",
    "        output_path=f\"{hptune_training_output_path}/{tuning_steps[i].name[9:]}/BestModel\",\n",
    "        base_transform_job_name = f\"{usecase}-evaluation-{tuning_steps[i].name[9:]}\",\n",
    "        env = {\"MODELS3LOCATION\":create_best_model_steps[i].properties.PrimaryContainer.ModelDataUrl, \n",
    "               \"MODELNAME\":build_parameters[\"model_specifications\"][f\"model{i}\"][\"model_name\"]}\n",
    "    )\n",
    "    evaluation_step = TransformStep(\n",
    "        name=f\"Evaluating-Best-{tuning_steps[i].name[9:]}-Model\",\n",
    "        transformer=transformer_dt,\n",
    "        inputs=TransformInput(data=step_process_evaluation.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri, \n",
    "                              # data_type = \"text/csv\"\n",
    "                             )\n",
    "    )\n",
    "    evaluation_steps.append(evaluation_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a6828b",
   "metadata": {},
   "source": [
    "### Getting the best model based on model performance metric on evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60729d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(n_models):\n",
    "    inputs.append(ProcessingInput(sagemaker.workflow.functions.Join(on='/', values=[evaluation_steps[i].properties.TransformOutput.S3OutputPath, \"evaluation.csv.out\"]), destination=f\"/opt/ml/processing/input/model{i}\"))\n",
    "# inputs = inputs + [ProcessingInput(sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", \"Model_Performance_Metrics.csv\"]), destination=f\"/opt/ml/processing/metrics\")]\n",
    "inputs = inputs + [ProcessingInput(source = sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_input_bucket, \"codes\", \"preprocessing_requirements.txt\"]), destination = \"/opt/ml/processing/input/requirements\")]\n",
    "# inputs = inputs + [ProcessingInput(source = sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_input_bucket, \"codes\", \"preprocessing_requirements.txt\"]), destination = \"/opt/ml/processing/input/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9607cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "property_file = PropertyFile(\n",
    "    name=\"property_file\",\n",
    "    output_name=\"property_file\",\n",
    "    path=\"property_file.json\"\n",
    ")\n",
    "\n",
    "step_get_best_model = ProcessingStep(\n",
    "    name = \"Getting-Best-Model\",\n",
    "    description = \"Picking the best model based on the metric value calculated using evaluation data\",\n",
    "    processor = sklearn_processor,\n",
    "    inputs=inputs,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"final_model\", source = \"/opt/ml/processing/final_model\", destination = evaluation_output_path),\n",
    "        ProcessingOutput(output_name=\"logs\", source = \"/opt/ml/processing/logs\", destination = evaluation_output_path),\n",
    "        ProcessingOutput(output_name=\"Metrics\", source = \"/opt/ml/processing/metrics_folder\", \n",
    "                         destination = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\"])\n",
    "                        ),\n",
    "                         # f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/\")\n",
    "        ProcessingOutput(output_name=\"Feature_Importance\", source = \"/opt/ml/processing/feature_importance\", \n",
    "                         destination = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\"])\n",
    "                        ),\n",
    "        ProcessingOutput(output_name=\"Confusion_Matrix\", source = \"/opt/ml/processing/confusion_matrix\", \n",
    "                         destination = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\"])\n",
    "                        ),\n",
    "        ProcessingOutput(output_name=\"Combined_Dashboard_Data\", source = \"/opt/ml/processing/Combined\", \n",
    "                         destination = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\"])\n",
    "                        ),\n",
    "        ProcessingOutput(output_name=\"property_file\", source = \"/opt/ml/processing/evaluation\", destination = evaluation_output_path)\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Training/Final_Model_Selection.py\",\n",
    "    code = f\"s3://{pipeline_input_bucket}/codes/{build_parameters['get_best_model_code_file_name']}\",\n",
    "    # depends_on = [step_dt_evaluation, step_lr_evaluation],\n",
    "    depends_on = evaluation_steps,\n",
    "    job_arguments = [\"--input_folder\", \"/opt/ml/processing/input\", \"--final_model_location\", \"/opt/ml/processing/final_model\", \n",
    "                     \"--logs_location\", \"/opt/ml/processing/logs\", \n",
    "                     # \"--model_metric_input_location\", \"/opt/ml/processing/metrics\", \n",
    "                     \"--model_metric_input_location\", sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", \"Model_Performance_Metrics.csv\"]),\n",
    "                     \"--model_metric_output_location\", \"/opt/ml/processing/metrics_folder\", \"--objective_metric\", objective_metric_name, \n",
    "                     \"--property_file_location\", \"/opt/ml/processing/evaluation\", \n",
    "                     \"--feature_importance_input_file_location\", sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", \"Feature_Importance.csv\"]),\n",
    "                     \"--feature_importance_output_file_location\", \"/opt/ml/processing/feature_importance\"\n",
    "                    ],\n",
    "    property_files=[property_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bf871",
   "metadata": {},
   "source": [
    "### Register best model in SageMaker model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40430678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "register_best_model_steps = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    if model_details[\"model_type\"] == 'sklearn_model':\n",
    "        estimator = SKLearn(entry_point = \"\", \n",
    "                            \n",
    "                            instance_type = model_details[\"instance_type\"],\n",
    "                            framework_version = '0.20.0', \n",
    "                            image_uri = sklearn_image_uri,\n",
    "                            \n",
    "                            role = role\n",
    "                            )\n",
    "        register_best_model_step = RegisterModel(name=f\"RegisterBest{model_details['model_name']}Model\", \n",
    "                              estimator = estimator, \n",
    "                              # model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_path),\n",
    "                              model_data=sagemaker.workflow.functions.Join(on='/', values=[step_get_best_model.properties.ProcessingOutputConfig.Outputs[\"final_model\"].S3Output.S3Uri, \"model.tar.gz\"]),\n",
    "                              content_types=[\"text/csv\"],\n",
    "                              response_types=[\"text/csv\"],\n",
    "                              inference_instances=[model_details[\"instance_type\"]],\n",
    "                              transform_instances=[model_details[\"instance_type\"]],\n",
    "                              model_package_group_name = build_parameters[\"model_package_group_name\"],\n",
    "                              image_uri = sklearn_image_uri,\n",
    "                              # approval_status=\"Approved\",\n",
    "                              role=role,\n",
    "                              depends_on = []\n",
    "                             )\n",
    "        register_best_model_steps.append(register_best_model_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "condition_steps = []\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    condition_equal = ConditionEquals(left = JsonGet(step_name=step_get_best_model.name, \n",
    "                                                   property_file=property_file, \n",
    "                                                   json_path=\"best_model_name\"),\n",
    "                                      right = model_details[\"model_name\"]\n",
    "                                     )\n",
    "    step_cond = ConditionStep(\n",
    "        name=f\"Is-{model_details['model_name']}-Best-Model\",\n",
    "        conditions=[condition_equal],\n",
    "        if_steps = [register_best_model_steps[i]],\n",
    "        )\n",
    "    condition_steps.append(step_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59255b21",
   "metadata": {},
   "source": [
    "### Model Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if build_parameters[\"given_model_type\"] == \"sklearn\":\n",
    "#     estimator = SKLearn(entry_point = \"\", \n",
    "                        \n",
    "#                         instance_type = build_parameters[\"scoring_instance_type\"],\n",
    "#                         framework_version = '0.20.0', \n",
    "#                         image_uri = sklearn_image_uri,\n",
    "                        \n",
    "#                         role = role\n",
    "#                         )\n",
    "    \n",
    "#     register_given_model_step = RegisterModel(name=f\"RegisterGivenModel\", \n",
    "#                                              estimator = estimator, \n",
    "#                                              # model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_path),\n",
    "#                                              model_data=build_parameters[\"given_model_path\"],\n",
    "#                                              content_types=[\"text/csv\"],\n",
    "#                                              response_types=[\"text/csv\"],\n",
    "#                                              inference_instances=[build_parameters[\"scoring_instance_type\"]],\n",
    "#                                              transform_instances=[build_parameters[\"scoring_instance_type\"]],\n",
    "#                                              model_package_group_name = build_parameters[\"model_package_group_name\"],\n",
    "#                                              image_uri = sklearn_image_uri,\n",
    "#                                              approval_status=\"Approved\",\n",
    "#                                              role=role,\n",
    "#                                              depends_on = []\n",
    "#                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_given_condition = ConditionEquals(left = build_parameters[\"model_given\"],\n",
    "#                                         right = \"No\"\n",
    "#                                        )\n",
    "# step_model_given_cond = ConditionStep(\n",
    "#     name=f\"Is-Model-Given\",\n",
    "#     conditions=[model_given_condition],\n",
    "#     # if_steps = [register_given_model_step],\n",
    "#     if_steps = [step_process] + tuning_steps + [step_process_evaluation] + create_best_model_steps + evaluation_steps + [step_get_best_model] + condition_steps,\n",
    "#     else_steps = [register_given_model_step]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf413c",
   "metadata": {},
   "source": [
    "### Arranging the steps inside pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d2ef643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"{usecase}-training\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        train_data,\n",
    "        test_data,\n",
    "        evaluation_data,\n",
    "        feature_selection_file,\n",
    "        pipeline_output_bucket,\n",
    "        #model_given,\n",
    "        #model_path,\n",
    "#         pipeline_output_path,\n",
    "        # processing_instance_count,\n",
    "        objective_metric_name,\n",
    "        # processing_code_location,\n",
    "        #training_instance_type,\n",
    "        #evaluation_instance_type,\n",
    "        processing_instance_type,\n",
    "        training_instance_type\n",
    "    ],\n",
    "#     steps=[step_process, step_process_evaluation, step_tuning_dt, step_tuning_lr, step_create_best_dt_model, step_cond],\n",
    "#     steps=[step_process_evaluation, step_process, step_tuning_dt, step_tuning_lr, step_create_best_dt_model, step_create_best_lr_model, step_dt_evaluation, step_lr_evaluation, step_cond]\n",
    "#     steps=[step_process, step_tuning_dt, step_process_evaluation, step_tuning_lr, step_create_best_dt_model, step_create_best_lr_model, step_dt_evaluation, step_lr_evaluation, step_get_best_model, step_register_best_model]\n",
    "#     steps = [step_cond]\n",
    "    steps = [step_process] + tuning_steps + [step_process_evaluation] + create_best_model_steps + evaluation_steps + [step_get_best_model] + condition_steps\n",
    "#     steps = [step_model_given_cond]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dfedf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"{build_parameters['usecase']}-training\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        train_data,\n",
    "        test_data,\n",
    "        evaluation_data,\n",
    "        feature_selection_file,\n",
    "        #model_given,\n",
    "        #model_path,\n",
    "#         pipeline_output_path,\n",
    "        # processing_instance_count,\n",
    "#         objective_metric_name,\n",
    "        # processing_code_location,\n",
    "        #training_instance_type,\n",
    "        #evaluation_instance_type,\n",
    "        processing_instance_type,\n",
    "#         training_instance_type\n",
    "    ],\n",
    "#     steps=[step_process, step_process_evaluation, step_tuning_dt, step_tuning_lr, step_create_best_dt_model, step_cond],\n",
    "#     steps=[step_process_evaluation, step_process, step_tuning_dt, step_tuning_lr, step_create_best_dt_model, step_create_best_lr_model, step_dt_evaluation, step_lr_evaluation, step_cond]\n",
    "#     steps=[step_process, step_tuning_dt, step_process_evaluation, step_tuning_lr, step_create_best_dt_model, step_create_best_lr_model, step_dt_evaluation, step_lr_evaluation, step_get_best_model, step_register_best_model]\n",
    "#     steps = [step_cond]\n",
    "    steps = [step_process] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97309e",
   "metadata": {},
   "source": [
    "### Uploading the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9a0832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:852619674999:pipeline/churn-training',\n",
       " 'ResponseMetadata': {'RequestId': '1ff119ca-bd8d-4bf1-8932-48d81c242ffa',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1ff119ca-bd8d-4bf1-8932-48d81c242ffa',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Tue, 02 May 2023 17:20:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18fb0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024dbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfc89d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
