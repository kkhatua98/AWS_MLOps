{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50eb784b",
   "metadata": {},
   "source": [
    "# Importing Libraries and Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ecb9e",
   "metadata": {},
   "source": [
    "https://github.com/aws/amazon-sagemaker-examples/issues/1207\n",
    "\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49344ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "# Taking pipeline building configurations from config.json.\n",
    "# These are only for building and will not be available at \n",
    "# the runtime of the pipeline.\n",
    "with open(\"config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec806df",
   "metadata": {},
   "source": [
    "# Setting Default Bucket and getting region and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31420ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Session.default_bucket of <sagemaker.session.Session object at 0x7fc1ab1a9550>>\n",
      "<bound method Session.default_bucket of <sagemaker.workflow.pipeline_context.PipelineSession object at 0x7fc1ab1a9510>>\n",
      "arn:aws:iam::720541911643:role/service-role/AmazonSageMaker-ExecutionRole-20230606T110107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Setting default bucket\n",
    "# Method 1\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "pipeline_session = PipelineSession(default_bucket = build_parameters[\"output_bucket\"])\n",
    "sagemaker_session = sagemaker.Session(default_bucket = build_parameters[\"output_bucket\"])\n",
    "\n",
    "# Method 2\n",
    "# pipeline_session.default_bucket = build_parameters[\"output_bucket\"]\n",
    "# sagemaker_session.default_bucket = build_parameters[\"output_bucket\"]\n",
    "\n",
    "# Method 3\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# bucket = \"sagemaker-output-bucket-us-east1\"   \n",
    "\n",
    "print(sagemaker_session.default_bucket)\n",
    "print(pipeline_session.default_bucket)\n",
    "\n",
    "\n",
    "## Getting region and role\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ad58d",
   "metadata": {},
   "source": [
    "# Input Data Location Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12eef6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Default location for the datasets\n",
    "train_data_uri = build_parameters[\"train_data\"]\n",
    "test_data_uri = build_parameters[\"test_data\"]\n",
    "evaluation_data_uri = build_parameters[\"evaluation_data\"]\n",
    "feature_selection_file_uri = build_parameters[\"feature_selection\"]\n",
    "\n",
    "\n",
    "# Parametrizing Data paths\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "train_data = ParameterString(name=\"TrainData\", default_value = train_data_uri)\n",
    "test_data = ParameterString(name=\"TestData\", default_value = test_data_uri)\n",
    "evaluation_data = ParameterString(name=\"EvaluationData\", default_value = evaluation_data_uri)\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = feature_selection_file_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea73f7b",
   "metadata": {},
   "source": [
    "#### Handling Output Locations\n",
    "See this link to learn more about pipeline execution variables: https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.execution_variables.ExecutionVariables\n",
    "pipeline_start_time is a execution vairable, so to create processig_output_path and inference_output_path we had to use sagemaker.workflow.functions.Join and we could not use Python f-strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c52228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline_output_bucket = build_parameters[\"output_bucket\"]\n",
    "\n",
    "pipeline_start_time = sagemaker.workflow.execution_variables.ExecutionVariables.START_DATETIME\n",
    "\n",
    "from sagemaker.workflow import functions\n",
    "train_processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"TrainProcessingOutput\"])\n",
    "validation_processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"ValidationProcessingOutput\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb815ac",
   "metadata": {},
   "source": [
    "# Step 1: Preprocessing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f4e77",
   "metadata": {},
   "source": [
    "#### 1.1 Loading preprocessing config.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b145a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_preprocessing_path = os.path.join(\"Pipeline_Component_Codes\",\"Training\",\"1_Preprocessing\")\n",
    "with open(os.path.join(local_preprocessing_path, \"config.json\")) as file:\n",
    "    processing_build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19e822",
   "metadata": {},
   "source": [
    "#### 1.2 Making parameter for processing machine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6a7434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=processing_build_parameters[\"machine_type\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0c092",
   "metadata": {},
   "source": [
    "#### 1.3 Building the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db093a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import Processor\n",
    "\n",
    "if processing_build_parameters[\"processing_type\"] == \"sklearn\":\n",
    "    processor = SKLearnProcessor(\n",
    "        framework_version = processing_build_parameters[\"framework_version\"],\n",
    "        instance_type = processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )\n",
    "elif processing_build_parameters[\"processing_type\"] == \"custom\":\n",
    "    processor = Processor(\n",
    "        image_uri = processing_build_parameters[\"image_uri\"],\n",
    "        instance_type = processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ff7fb",
   "metadata": {},
   "source": [
    "#### 1.4 Building preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2190cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name = \"preprocessing_full_data\",\n",
    "    description = \"Data preprocessing and splitting into train and test set\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source = train_data, destination=\"/opt/ml/processing/input/data\"),  \n",
    "        ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        # Train\n",
    "        ProcessingOutput(output_name = \"train\", source=\"/opt/ml/processing/train\", \n",
    "                         destination = train_processing_output_path\n",
    "                        ),\n",
    "        # Test\n",
    "        ProcessingOutput(output_name = \"test\", source=\"/opt/ml/processing/test\", \n",
    "                         destination = train_processing_output_path\n",
    "                        ),\n",
    "        # Logs\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "                         destination = train_processing_output_path\n",
    "                        ),\n",
    "    ],\n",
    "    code=os.path.join(local_preprocessing_path, processing_build_parameters[\"entry_point\"]),\n",
    "    job_arguments = [\"--train_data_location\", \"/opt/ml/processing/input/data\", \n",
    "                     \"--feature_selection_file_location\", \"/opt/ml/processing/input/feature_selection/Feature_Selection.csv\", \n",
    "                     \"--target_column\", \"Churn\",\n",
    "                     \"--preprocessed_train_data_location\", \"/opt/ml/processing/train\", \n",
    "                     \"--preprocessed_test_data_location\", \"/opt/ml/processing/test\", \n",
    "                     \"--log_location\", \"/opt/ml/processing/logss\"\n",
    "                    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01502d39",
   "metadata": {},
   "source": [
    "# Step 2: Processing Evaluation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f0102",
   "metadata": {},
   "source": [
    "#### 2.1 Loading preprocessing config.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ddaacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_val_processing_path = os.path.join(\"Pipeline_Component_Codes\",\"Training\",\"11_Validation_Processing\")\n",
    "with open(os.path.join(local_val_processing_path, \"config.json\")) as file:\n",
    "    val_processing_build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3886e",
   "metadata": {},
   "source": [
    "#### 2.2 Making parameter for processing machine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bb90ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_processing_instance_type = ParameterString(\n",
    "    name=\"ValProcessingInstanceType\",\n",
    "    default_value=val_processing_build_parameters[\"machine_type\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d06cd",
   "metadata": {},
   "source": [
    "#### 2.3 Building the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d307fa8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import Processor\n",
    "\n",
    "if val_processing_build_parameters[\"processing_type\"] == \"sklearn\":\n",
    "    processor = SKLearnProcessor(\n",
    "        framework_version = val_processing_build_parameters[\"framework_version\"],\n",
    "        instance_type = val_processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = val_processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )\n",
    "elif processing_build_parameters[\"processing_type\"] == \"custom\":\n",
    "    processor = Processor(\n",
    "        image_uri = val_processing_build_parameters[\"image_uri\"],\n",
    "        instance_type = val_processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = val_processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7267ca",
   "metadata": {},
   "source": [
    "#### 2.4 Building preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69accd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "step_val_process = ProcessingStep(\n",
    "    name = \"preprocessing_validation_data\",\n",
    "    description = \"Validation data preprocessing.\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source = evaluation_data, destination=\"/opt/ml/processing/input/data\"),  \n",
    "        ProcessingInput(source = feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        # Evaluation data\n",
    "        ProcessingOutput(output_name = \"evaluation\", source=\"/opt/ml/processing/test\", \n",
    "                         destination = validation_processing_output_path\n",
    "                        ),\n",
    "        # Logs\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "                         destination = validation_processing_output_path\n",
    "                        ),\n",
    "    ],\n",
    "    code=os.path.join(local_val_processing_path, val_processing_build_parameters[\"entry_point\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3a46e",
   "metadata": {},
   "source": [
    "# Step 3: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3134418",
   "metadata": {},
   "source": [
    "#### 3.1 Getting models from Local Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd98bf02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Logistic_Regression', 'Decision_Tree']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "local_models_path = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"2_Models_HPTune\")\n",
    "models = []\n",
    "for directory in os.listdir(local_models_path):\n",
    "    if '.' not in directory: # Avoiding .ipynb_checkpoints\n",
    "        models.append(directory)\n",
    "\n",
    "models = models[1:]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6a268",
   "metadata": {},
   "source": [
    "#### 3.2 Reading config.json Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386fa9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_details = {}\n",
    "for model in models:\n",
    "    with open(os.path.join(local_models_path, model, \"config.json\")) as file:\n",
    "        model_build_parameters = json.load(file)\n",
    "    model_details[model] = model_build_parameters\n",
    "\n",
    "# print(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c018c",
   "metadata": {},
   "source": [
    "#### 3.2 Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "670ed605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Machine types\n",
    "training_instances = []\n",
    "for model in models:\n",
    "    training_instance_type = ParameterString(\n",
    "        name=f\"{model}_InstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "    training_instances.append(training_instance_type)\n",
    "\n",
    "# Objective metric\n",
    "# objective_metric_name = ParameterString(name = \"ObjectiveMetric\", default_value = build_parameters[\"objective_metric\"])\n",
    "# metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"accuracy:([0-9\\\\.]+)\"}]\n",
    "\n",
    "objective_metric_name = \"validation:accuracy\"\n",
    "metric_definitions = [{'Name': \"validation:accuracy\", 'Regex': \"accuracy:([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e8f2d",
   "metadata": {},
   "source": [
    "#### 3.3 Creating the Estimators on which Tuning Will Happen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc300d",
   "metadata": {},
   "source": [
    "Sagemaker provides us docker conatiners for all the popular algorithms like they have scikit learn image for all the Scikit learn models, they have XGBoost image and they also have deep learning images as well. Here for the demo purpose we have used only three models, Logistic Regression, Decision Tree and XGBoost. So our need was not to build our own image. If any other Python library is needed we can mention those in **requirements.txt** file. We do not have to do anything more, pipeline will automatically install those in respective containers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4788777a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "from sagemaker.workflow import functions\n",
    "\n",
    "\n",
    "\n",
    "tuning_steps = []\n",
    "index = -1\n",
    "for model in models:\n",
    "    index = index + 1\n",
    "    current_model_details = model_details[model]\n",
    "    \n",
    "    output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"HPTuningOutputs\", model])\n",
    "    \n",
    "    # Creating the Estimators on which Tuning Will Happen\n",
    "    if current_model_details['model_type'] == 'sklearn_model':\n",
    "        estimator = SKLearn(\n",
    "                            source_dir = os.path.join(local_models_path, model),\n",
    "                            entry_point = current_model_details[\"entry_point\"], \n",
    "                            instance_type = training_instances[index], \n",
    "                            instance_count = 1,\n",
    "                            framework_version = current_model_details[\"framework_version\"], \n",
    "                            role = role,\n",
    "                            output_path = output_path\n",
    "                            )\n",
    "    elif current_model_details['model_type'] == 'xgboost_model':\n",
    "        estimator = XGBoost(\n",
    "                            source_dir = os.path.join(local_models_path, model),\n",
    "                            entry_point = current_model_details[\"entry_point\"],\n",
    "                            instance_type = training_instances[index],\n",
    "                            instance_count = 1,\n",
    "                            framework_version = current_model_details[\"framework_version\"],\n",
    "                            role=role,\n",
    "                            output_path = output_path\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    # Getting the hyperparameters\n",
    "    hyperparameters = current_model_details[\"hyperparameters\"]\n",
    "    \n",
    "    hyperparameter_ranges = {}\n",
    "    for hyperparameter in hyperparameters:\n",
    "        if hyperparameters[hyperparameter][\"type\"] == \"continuous\":\n",
    "            hyperparameter_ranges[hyperparameter] = ContinuousParameter(min_value = hyperparameters[hyperparameter][\"min_value\"],\n",
    "                                                                        max_value = hyperparameters[hyperparameter][\"max_value\"],\n",
    "                                                                        scaling_type = hyperparameters[hyperparameter][\"scaling_type\"])\n",
    "        elif hyperparameters[hyperparameter][\"type\"] == \"categorical\":\n",
    "            hyperparameter_ranges[hyperparameter] = CategoricalParameter(hyperparameters[hyperparameter][\"values\"])\n",
    "        elif hyperparameters[hyperparameter][\"type\"] == \"integer\":\n",
    "            hyperparameter_ranges[hyperparameter] = IntegerParameter(min_value = hyperparameters[hyperparameter][\"min_value\"],\n",
    "                                                                     max_value = hyperparameters[hyperparameter][\"max_value\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Making the hyperparameter tuner\n",
    "    tuner = HyperparameterTuner(\n",
    "        estimator = estimator,\n",
    "        objective_metric_name = objective_metric_name,\n",
    "        hyperparameter_ranges = hyperparameter_ranges,\n",
    "        metric_definitions = metric_definitions,\n",
    "        max_jobs=1,\n",
    "        max_parallel_jobs=1,\n",
    "        strategy = current_model_details[\"tuning_strategy\"],\n",
    "        base_tuning_job_name = current_model_details[\"model_name\"]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Building the tuning step\n",
    "    step_tuning = TuningStep(\n",
    "        name = f\"hptuning_{current_model_details['model_name']}\",\n",
    "        tuner = tuner,\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            ),\n",
    "            \"test\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    tuning_steps.append(step_tuning)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f3955",
   "metadata": {},
   "source": [
    "# Step: 4: Getting the best model from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffcec9",
   "metadata": {},
   "source": [
    "Follow this link to get example of how to write lambda step https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-pipelines/tabular/lambda-step/sagemaker-pipelines-lambda-step.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc723c7",
   "metadata": {},
   "source": [
    "#### 4.1 Building the Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a52b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "\n",
    "func = Lambda(\n",
    "    function_name = \"get_best_model_from_hptune_job\",\n",
    "    execution_role_arn=build_parameters[\"role_given_to_lambda\"],\n",
    "#     execution_role_arn = role,\n",
    "#     execution_role_arn = lambda_role,\n",
    "    script = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"3_HPTune_Best_Model\", \"main.py\"),\n",
    "    handler=\"main.main\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c1530",
   "metadata": {},
   "source": [
    "#### 4.2 Building the Lambdastep\n",
    "See this link to get the idea on how tuning step name is being fetched (tuning_steps[i].properties.HyperParameterTuningJobName): https://boto3.amazonaws.com/v1/documentation/api/1.9.46/reference/services/sagemaker.html#SageMaker.Client.describe_hyper_parameter_tuning_job \n",
    "In the same way other properties can also be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91105ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaOutput, LambdaStep, LambdaOutputTypeEnum\n",
    "\n",
    "best_model_steps = []\n",
    "for i in range(len(models)):\n",
    "    # Building the outputs\n",
    "    output_param_1 = LambdaOutput(output_name=f\"best_model_location\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_2 = LambdaOutput(output_name=f\"best_metric_value\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_3 = LambdaOutput(output_name=f\"best_model\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_4 = LambdaOutput(output_name=f\"best_training_job_container\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_5 = LambdaOutput(output_name=f\"best_instance_type\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_6 = LambdaOutput(output_name=f\"best_metrics_path\", output_type=LambdaOutputTypeEnum.String)\n",
    "    \n",
    "    # Building the Lambdastep\n",
    "    step_deploy_lambda = LambdaStep(\n",
    "        name=f\"get_best_{models[i]}_model\",\n",
    "        lambda_func=func,\n",
    "        inputs={\n",
    "            \"tuning_job_name\": tuning_steps[i].properties.HyperParameterTuningJobName\n",
    "        },\n",
    "#         outputs=[output_param_1, output_param_2],\n",
    "        outputs=[output_param_1, output_param_2, output_param_3, output_param_4, output_param_5, output_param_6]\n",
    "    )\n",
    "    \n",
    "    best_model_steps.append(step_deploy_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06430a9",
   "metadata": {},
   "source": [
    "# Step 5: Evaluating the best models from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc260b22",
   "metadata": {},
   "source": [
    "#### Building Property Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ee4888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_reports = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    evaluation_report = PropertyFile(\n",
    "        name = f\"evaluating_best_{models[i]}_model\",\n",
    "        output_name = \"evaluation\",\n",
    "        path = \"evaluation.json\"\n",
    "    )\n",
    "    \n",
    "    evaluation_reports.append(evaluation_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5678860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "evaluation_steps = []\n",
    "for i in range(len(models)):\n",
    "    \n",
    "    # Building evaluator\n",
    "    current_model_details = model_details[models[i]]\n",
    "    print(current_model_details['model_type'])\n",
    "    \n",
    "    if current_model_details['model_type'] == 'sklearn_model':\n",
    "        evaluator = SKLearnProcessor(\n",
    "        framework_version = current_model_details[\"framework_version\"],\n",
    "        instance_type = training_instances[i],\n",
    "        instance_count = 1,\n",
    "        role=role\n",
    "        )\n",
    "    elif current_model_details['model_type'] != 'sklearn_model':\n",
    "        # Logic is not complete\n",
    "        evaluator = Processor(\n",
    "            image_uri = processing_build_parameters[\"image_uri\"],\n",
    "            instance_type = processing_build_parameters[\"machine_tyLLpe\"],\n",
    "            instance_count = processing_build_parameters[\"machine_count\"],\n",
    "            base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "            role=role\n",
    "        )\n",
    "    \n",
    "    output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"EvaluationOutputs\", models[i]])\n",
    "    \n",
    "    # Building the evaluation step\n",
    "    step_evaluation = ProcessingStep(\n",
    "        name = f\"evaluating_best_{models[i]}_model\",\n",
    "        description = f\"Evaluating best {models[i]} model.\",\n",
    "        processor = evaluator,\n",
    "        inputs=[\n",
    "            # Inputs will be 1. evaluation data and 2. model to be evaluated.\n",
    "            ProcessingInput(source = step_val_process.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri, destination=\"/opt/ml/processing/input/data\"), # 1\n",
    "            ProcessingInput(source = best_model_steps[i].properties.Outputs[\"best_model_location\"], destination=\"/opt/ml/processing/input/model\") # 2\n",
    "        ],\n",
    "        outputs=[\n",
    "            # Three output files will be generated.\n",
    "            # 1. A file containing all the model evaluation metrics that will be shown in the Model Registry.\n",
    "            ProcessingOutput(output_name=\"metrics\",\n",
    "                             source=\"/opt/ml/processing/metrics\",\n",
    "                             destination = output_path\n",
    "                            ),\n",
    "            # 2. A file containing evaluation outputs that will be sent to.\n",
    "            ProcessingOutput(output_name=\"evaluation\",\n",
    "                             source=\"/opt/ml/processing/test\",\n",
    "                             destination = output_path\n",
    "                            ),\n",
    "            # 2. Logs\n",
    "            ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "                             destination = output_path\n",
    "                            )\n",
    "        ],\n",
    "        code = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"4_Model_Evaluation\", \"main.py\"),\n",
    "        property_files=[evaluation_reports[i]],\n",
    "        job_arguments = [\n",
    "            \"--objective_metric\", build_parameters[\"objective_metric\"],  # This can be accuracy, precision etc. Models will be evaluated based on this metric.\n",
    "            \"--model_name\", models[i],  # This argument will not be used in the code, this will be written in the output 1 file as it is.\n",
    "            \"--best_model_location\", best_model_steps[i].properties.Outputs[\"best_model_location\"],  # This argument will not be used in the code, this will be written in the output 1 file as it is.\n",
    "            \"--best_training_job_container\", best_model_steps[i].properties.Outputs[\"best_training_job_container\"],  # This argument will not be used in the code, this will be written in the output 1 file as it is.\n",
    "            \"--best_instance_type\", best_model_steps[i].properties.Outputs[\"best_instance_type\"]  # This argument will not be used in the code, this will be written in the output 1 file as it is.\n",
    "            ]\n",
    "    )\n",
    "    \n",
    "    evaluation_steps.append(step_evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6750a",
   "metadata": {},
   "source": [
    "# Step 6: Getting the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09f202",
   "metadata": {},
   "source": [
    "#### Building the Lambda Function\n",
    "We could have develop another Lambda function to accomplish this job, but we have written the logic of this task in the previous lambda function (where we are getting the final model from each hyperparameter tuning job), so that we have to maintain only one Lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8c61e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# get_final_model_func = Lambda(\n",
    "#     function_name = \"get_final_model\",\n",
    "#     execution_role_arn=build_parameters[\"role_given_to_lambda\"],\n",
    "# #     execution_role_arn = role,\n",
    "# #     execution_role_arn = lambda_role,\n",
    "#     script = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"3_HPTune_Best_Model\", \"main.py\"),\n",
    "#     handler=\"main.main\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ed1d1",
   "metadata": {},
   "source": [
    "#### Building the Lambdastep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9975c600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# output_param_1 = LambdaOutput(output_name=f\"final_model_location\", output_type=LambdaOutputTypeEnum.String)\n",
    "# output_param_2 = LambdaOutput(output_name=f\"final_metric_value\", output_type=LambdaOutputTypeEnum.String)\n",
    "# output_param_3 = LambdaOutput(output_name=f\"final_model\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=f\"best_model_location\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=f\"best_metric_value\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=f\"best_model\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_4 = LambdaOutput(output_name=f\"best_training_job_container\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_5 = LambdaOutput(output_name=f\"best_instance_type\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_6 = LambdaOutput(output_name=f\"best_metrics_path\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "\n",
    "lambda_inputs = {'n':len(models)}\n",
    "for i in range(len(models)):\n",
    "    best_model_location = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_model_location\")\n",
    "    metrics = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_metric_value\")\n",
    "    model = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_model\")\n",
    "    \n",
    "    best_training_job_container = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_training_job_container\")\n",
    "    best_instance_type = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_instance_type\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    lambda_inputs[f\"best_model_location{i}\"] = best_model_location\n",
    "    lambda_inputs[f\"metrics{i}\"] = metrics\n",
    "    lambda_inputs[f\"model{i}\"] = model\n",
    "    \n",
    "    lambda_inputs[f\"best_training_job_container{i}\"] = best_training_job_container\n",
    "    lambda_inputs[f\"best_instance_type{i}\"] = best_instance_type\n",
    "    lambda_inputs[f\"metrics_path{i}\"] = evaluation_steps[i].properties.ProcessingOutputConfig.Outputs[\"metrics\"].S3Output.S3Uri\n",
    "\n",
    "\n",
    "    \n",
    "step_final_model = LambdaStep(\n",
    "    name=f\"get_final_model\",\n",
    "    lambda_func=func,\n",
    "    inputs = lambda_inputs,\n",
    "    outputs=[output_param_1, output_param_2, output_param_3, output_param_4, output_param_5, output_param_6]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937fb627",
   "metadata": {},
   "source": [
    "# Step 8: Register best model in SageMaker model registry\n",
    "Yes, we have to build step 8 before step 7. Step 7 will be a condition step and to define a condition step we have to first define what is the step which will be executed, if the condition in condition step is true and which is the step that will be if the condition is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cbb44cf-5c5c-4b97-ace4-aee7043b43c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource, FileSource\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(\n",
    "    entry_point = \"\",\n",
    "    # instance_type = step_final_model.properties.Outputs[\"best_instance_type\"],\n",
    "    image_uri = step_final_model.properties.Outputs[\"best_training_job_container\"],\n",
    "    role = role\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "        model_statistics = MetricsSource(\n",
    "            # s3_uri = evaluation_steps[i].properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "            s3_uri = Join(on=\"/\", values=[step_final_model.properties.Outputs[\"best_metrics_path\"], \"metrics.json\"]),\n",
    "            # s3_uri = \"s3://demo-output-bucket/Training_Pipeline_Output/2023-08-03T11:33:25.698Z/EvaluationOutputs/Decision_Tree/metrics.json\",\n",
    "            # s3_uri = Join(on=\"/\", values=[step_evaluate_model.arguments[\"Outputs\"][0][\"S3Output\"][\"S3Uri\"], \"evaluation.json\"])\n",
    "            content_type = \"application/json\"\n",
    "        )\n",
    ")\n",
    "\n",
    "    \n",
    "register_best_model_step = RegisterModel(\n",
    "    name=f\"RegisterFinalModel\",\n",
    "    estimator = estimator, \n",
    "    # model_data=step_final_model.properties.Outputs[\"final_model_location\"],\n",
    "    model_data=step_final_model.properties.Outputs[\"best_model_location\"],\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[step_final_model.properties.Outputs[\"best_instance_type\"]],\n",
    "    transform_instances=[step_final_model.properties.Outputs[\"best_instance_type\"]],\n",
    "    model_package_group_name = build_parameters[\"model_package_group_name\"],\n",
    "    # image_uri = step_final_model.properties.Outputs[\"best_training_job_container\"],\n",
    "    # approval_status=\"Approved\",\n",
    "    role=role,\n",
    "    depends_on = [],\n",
    "    model_metrics = model_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8745051",
   "metadata": {},
   "source": [
    "# Building the Pipeline\n",
    "#### Arranging the steps inside pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cec6e5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"{build_parameters['usecase']}-training\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[train_data, test_data, evaluation_data, feature_selection_file, \n",
    "                processing_instance_type] + training_instances + [objective_metric_name],\n",
    "    # steps = [step_process, step_val_process] + tuning_steps + best_model_steps + evaluation_steps + [step_final_model] + condition_steps,\n",
    "    steps = [step_process, step_val_process] + tuning_steps + best_model_steps + evaluation_steps + [step_final_model] + [register_best_model_step],\n",
    "    sagemaker_session = pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f578e",
   "metadata": {},
   "source": [
    "#### Uploading the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d694fbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-south-1:720541911643:pipeline/churn-training',\n",
       " 'ResponseMetadata': {'RequestId': 'eade4705-9c7e-4baa-ae78-32e27a1002b5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'eade4705-9c7e-4baa-ae78-32e27a1002b5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '83',\n",
       "   'date': 'Tue, 22 Aug 2023 04:02:31 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37659dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
