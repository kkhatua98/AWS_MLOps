{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03c5c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\n",
      "<sagemaker.session.Session object at 0x7f2c70abc940>\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "# sagemaker_session = sagemaker.session.Session(default_bucket = pipeline_output_bucket)\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = \"arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\"\n",
    "\n",
    "print(role)\n",
    "print(sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfb0aa",
   "metadata": {},
   "source": [
    "### Taking configuration parameter values from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176b4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the configurations from config.json file.\n",
    "import json\n",
    "with open(\"../config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b35e1d",
   "metadata": {},
   "source": [
    "### Handling Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_uri = build_parameters[\"scoring_data_s3_location\"]\n",
    "\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "batch_data = ParameterString(name=\"BatchData\", default_value=batch_data_uri)\n",
    "\n",
    "input_feature_selection_file_uri = build_parameters[\"feature_selection_file_s3_location\"]\n",
    "# preprocessing_code_location_uri = f\"s3://{pipeline_input_bucket}/codes/Training_Preprocessing.py\"\n",
    "\n",
    "# Basic feature selection file path\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = input_feature_selection_file_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2168f",
   "metadata": {},
   "source": [
    "### Handling Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c18a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_output_bucket = build_parameters[\"output_bucket\"] \n",
    "sagemaker_session.default_bucket = pipeline_output_bucket\n",
    "\n",
    "from time import gmtime, strftime\n",
    "pipeline_start_time = strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "processing_output_path = f\"s3://{pipeline_output_bucket}/Scoring_Pipeline_Output/{pipeline_start_time}/ProcessingOutput\"\n",
    "inference_output_path = f\"s3://{pipeline_output_bucket}/Scoring_Pipeline_Output/{pipeline_start_time}/InferenceOutput\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9968614",
   "metadata": {},
   "source": [
    "### Building the Preprocessing Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6834ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = build_parameters[\"sklearn_processor_framework_version\"]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=build_parameters[\"scoring_preprocessing_instance_type\"],\n",
    "    instance_count=build_parameters[\"scoring_preprocessing_instance_count\"],\n",
    "    base_job_name=\"Churn-Inference-Preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, TuningStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=batch_data, destination=\"/opt/ml/processing/input\"),  \n",
    "      ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = processing_output_path),\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", destination = processing_output_path)\n",
    "    ],\n",
    "    code=\"../SageMaker_Pipeline_Component_Codes/Scoring/Scoring_Preprocessing.py\",\n",
    "    job_arguments = [\"--batch_data_location\", \"/opt/ml/processing/input\", \"--target_column\", \"Churn\",\n",
    "                     \"--feature_selection_file_location\", \"/opt/ml/processing/input/feature_selection\"\n",
    "                     \"--preprocessed_batch_data_location\", \"/opt/ml/processing/train\", \"--log_location\", \"/opt/ml/processing/logss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e69590",
   "metadata": {},
   "source": [
    "### Get Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07d99bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageGroupName': 'churn-packagegroup', 'ModelPackageVersion': 5, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:852619674999:model-package/churn-packagegroup/5', 'CreationTime': datetime.datetime(2022, 6, 30, 7, 40, 14, 674000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'PendingManualApproval'}\n",
      "arn:aws:sagemaker:us-east-1:852619674999:model-package/churn-packagegroup/5\n"
     ]
    }
   ],
   "source": [
    "#### Obtaining the model from Sagemaker model registry.\n",
    "package_group = build_parameters[\"model_package_group_name\"]\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker')\n",
    "model_packages = client.list_model_packages(ModelPackageGroupName = package_group)\n",
    "\n",
    "\n",
    "latest_package = model_packages[\"ModelPackageSummaryList\"][0]\n",
    "latest_package_arn = latest_package[\"ModelPackageArn\"]\n",
    "\n",
    "print(latest_package)\n",
    "print(latest_package_arn)\n",
    "\n",
    "\n",
    "latest_package_details = client.describe_model_package(ModelPackageName=latest_package_arn)\n",
    "\n",
    "from sagemaker.model import Model\n",
    "inference_model = Model(image_uri = latest_package_details['InferenceSpecification']['Containers'][0]['Image'], \n",
    "#                         entry_point=\"../\" + build_parameters[\"scoring_code_loaction\"], \n",
    "                        model_data = latest_package_details['InferenceSpecification']['Containers'][0][\"ModelDataUrl\"], \n",
    "                        role = role,\n",
    "                        sagemaker_session = sagemaker_session\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=build_parameters[\"scoring_instance_type\"],\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"Get-Model\",\n",
    "    model=inference_model,\n",
    "    inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_package_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0484a3a1",
   "metadata": {},
   "source": [
    "### Making Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "119a0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=build_parameters[\"scoring_instance_type\"],\n",
    "    instance_count=1,\n",
    "    output_path=inference_output_path,\n",
    "    base_transform_job_name = \"Churn-Transformation\"\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"Inference\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                          # data_type = \"text/csv\"\n",
    "                         )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5787e",
   "metadata": {},
   "source": [
    "### Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b848835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"Churn-Scoring\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        batch_data,\n",
    "        feature_selection_file\n",
    "    ],\n",
    "    steps=[step_process, \n",
    "           step_create_model, \n",
    "#            step_transform\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b01ed",
   "metadata": {},
   "source": [
    "### Uploading the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f7efab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:852619674999:pipeline/churn-scoring',\n",
       " 'ResponseMetadata': {'RequestId': 'ce546728-853c-4adc-b60f-3bf4ab90b560',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ce546728-853c-4adc-b60f-3bf4ab90b560',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '81',\n",
       "   'date': 'Thu, 30 Jun 2022 11:34:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce58e8",
   "metadata": {},
   "source": [
    "### Building pipeline parameters. When we run the pipeline we can set these parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_uri = \"s3://demo-bucket-test-mlop/Churn_Demo/churn-bigml-20.csv\"\n",
    "\n",
    "from time import gmtime, strftime\n",
    "output_path = f\"s3://{default_bucket}/ChurnTrain/\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "print(output_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "inference_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "pipeline_output_path = ParameterString(\n",
    "    name=\"OutputPath\",\n",
    "    default_value=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d421b7e5",
   "metadata": {},
   "source": [
    "### Building the Preprocessing component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c65588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"Churn-Inference-Preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, TuningStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=batch_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\")\n",
    "    ],\n",
    "    code=\"SageMaker_Pipeline_Component_Codes/Scoring/Scoring_Preprocessing.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13515240",
   "metadata": {},
   "source": [
    "### Get model step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Obtaining the model from Sagemaker model registry.\n",
    "package_group = \"ChurnPackageGroup\"\n",
    "model_packages = client.list_model_packages(ModelPackageGroupName = package_group)\n",
    "\n",
    "\n",
    "latest_package = model_packages[\"ModelPackageSummaryList\"][0]\n",
    "latest_package_arn = latest_package[\"ModelPackageArn\"]\n",
    "\n",
    "print(latest_package)\n",
    "print(latest_package_arn)\n",
    "\n",
    "\n",
    "latest_package_details = client.describe_model_package(ModelPackageName=latest_package_arn)\n",
    "\n",
    "from sagemaker.model import Model\n",
    "inference_model = Model(image_uri = latest_package_details['InferenceSpecification']['Containers'][0]['Image'], \n",
    "                        entry_point='SageMaker_Pipeline_Component_Codes/Scoring/inference.py', \n",
    "                        model_data = latest_package_details['InferenceSpecification']['Containers'][0][\"ModelDataUrl\"], \n",
    "                        role = role,\n",
    "                        sagemaker_session = sagemaker_session\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=inference_instance_type,\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"Get-Model\",\n",
    "    model=inference_model,\n",
    "    inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca6ba2",
   "metadata": {},
   "source": [
    "### Making inference step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=inference_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=pipeline_output_path,\n",
    "    base_transform_job_name = \"Churn-Transformation\"\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"Inference\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                          # data_type = \"text/csv\"\n",
    "                         )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abfc508",
   "metadata": {},
   "source": [
    "### Building the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f966550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"Churn-Scoring\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        batch_data,\n",
    "        pipeline_output_path,\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        inference_instance_type\n",
    "    ],\n",
    "    steps=[step_process, step_create_model, step_transform]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a7dce",
   "metadata": {},
   "source": [
    "### Uploading the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
