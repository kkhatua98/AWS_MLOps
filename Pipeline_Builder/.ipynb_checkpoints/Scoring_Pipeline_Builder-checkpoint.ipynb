{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65cb5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\n",
      "<sagemaker.session.Session object at 0x7f3d71032e10>\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "# sagemaker_session = sagemaker.session.Session(default_bucket = pipeline_output_bucket)\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = \"arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\"\n",
    "\n",
    "print(role)\n",
    "print(sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664183b",
   "metadata": {},
   "source": [
    "### Taking configuration parameter values from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac92560",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the configurations from config.json file.\n",
    "import json\n",
    "with open(\"../config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095e0e4",
   "metadata": {},
   "source": [
    "### Handling Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6609dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_input_bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dbbb9fb2fab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameterString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BatchData\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_data_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_feature_selection_file_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"s3://{pipeline_input_bucket}/Feature_Selection.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# preprocessing_code_location_uri = f\"s3://{pipeline_input_bucket}/codes/Training_Preprocessing.py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline_input_bucket' is not defined"
     ]
    }
   ],
   "source": [
    "batch_data_uri = build_parameters[\"scoring_data_s3_location\"]\n",
    "\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "batch_data = ParameterString(name=\"BatchData\", default_value=batch_data_uri)\n",
    "\n",
    "input_feature_selection_file_uri = build_parameters[\"feature_selection_file_s3_location\"]\n",
    "# preprocessing_code_location_uri = f\"s3://{pipeline_input_bucket}/codes/Training_Preprocessing.py\"\n",
    "\n",
    "# Basic feature selection file path\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = input_feature_selection_file_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29012104",
   "metadata": {},
   "source": [
    "### Handling Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24030031",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_output_bucket = build_parameters[\"output_bucket\"] \n",
    "sagemaker_session.default_bucket = pipeline_output_bucket\n",
    "\n",
    "from time import gmtime, strftime\n",
    "pipeline_start_time = strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "processing_output_path = f\"s3://{pipeline_output_bucket}/Scoring_Pipeline_Output/{pipeline_start_time}/ProcessingOutput\"\n",
    "inference_output_path = f\"s3://{pipeline_output_bucket}/Scoring_Pipeline_Output/{pipeline_start_time}/InferenceOutput\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c279b89",
   "metadata": {},
   "source": [
    "### Building the Preprocessing Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35109333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = build_parameters[\"sklearn_processor_framework_version\"]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=build_parameters[\"scoring_preprocessing_instance_type\"],\n",
    "    instance_count=build_parameters[\"scoring_preprocessing_instance_count\"],\n",
    "    base_job_name=\"Churn-Inference-Preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, TuningStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=batch_data, destination=\"/opt/ml/processing/input\"),  \n",
    "      ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = processing_output_path),\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", destination = processing_output_path)\n",
    "    ],\n",
    "    code=\"SageMaker_Pipeline_Component_Codes/Scoring/Scoring_Preprocessing.py\",\n",
    "    job_arguments = [\"--batch_data_location\", \"/opt/ml/processing/input\", \"--target_column\", \"Churn\",\n",
    "                     \"--feature_selection_file_location\", \"/opt/ml/processing/input/feature_selection\"\n",
    "                     \"--preprocessed_batch_data_location\", \"/opt/ml/processing/train\", \"--log_location\", \"/opt/ml/processing/logss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d2a65",
   "metadata": {},
   "source": [
    "### Get Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Obtaining the model from Sagemaker model registry.\n",
    "package_group = build_parameters[\"model_package_group_name\"]\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker')\n",
    "model_packages = client.list_model_packages(ModelPackageGroupName = package_group)\n",
    "\n",
    "\n",
    "latest_package = model_packages[\"ModelPackageSummaryList\"][0]\n",
    "latest_package_arn = latest_package[\"ModelPackageArn\"]\n",
    "\n",
    "print(latest_package)\n",
    "print(latest_package_arn)\n",
    "\n",
    "\n",
    "latest_package_details = client.describe_model_package(ModelPackageName=latest_package_arn)\n",
    "\n",
    "from sagemaker.model import Model\n",
    "inference_model = Model(image_uri = latest_package_details['InferenceSpecification']['Containers'][0]['Image'], \n",
    "                        entry_point=build_parameters[\"scoring_code_loaction\"], \n",
    "                        model_data = latest_package_details['InferenceSpecification']['Containers'][0][\"ModelDataUrl\"], \n",
    "                        role = role,\n",
    "                        sagemaker_session = sagemaker_session\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=build_parameters[\"scoring_instance_type\"],\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"Get-Model\",\n",
    "    model=inference_model,\n",
    "    inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bbcf1",
   "metadata": {},
   "source": [
    "### Making Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47055d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=build_parameters[\"scoring_instance_type\"],\n",
    "    instance_count=1,\n",
    "    output_path=inference_output_path,\n",
    "    base_transform_job_name = \"Churn-Transformation\"\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"Inference\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                          # data_type = \"text/csv\"\n",
    "                         )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee815238",
   "metadata": {},
   "source": [
    "### Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"Churn-Scoring\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        batch_data\n",
    "    ],\n",
    "    steps=[step_process, step_create_model, step_transform]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30054539",
   "metadata": {},
   "source": [
    "### Building pipeline parameters. When we run the pipeline we can set these parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_uri = \"s3://demo-bucket-test-mlop/Churn_Demo/churn-bigml-20.csv\"\n",
    "\n",
    "from time import gmtime, strftime\n",
    "output_path = f\"s3://{default_bucket}/ChurnTrain/\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "print(output_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "inference_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "pipeline_output_path = ParameterString(\n",
    "    name=\"OutputPath\",\n",
    "    default_value=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c39139",
   "metadata": {},
   "source": [
    "### Building the Preprocessing component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"Churn-Inference-Preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, TuningStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=batch_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\")\n",
    "    ],\n",
    "    code=\"SageMaker_Pipeline_Component_Codes/Scoring/Scoring_Preprocessing.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a33ab",
   "metadata": {},
   "source": [
    "### Get model step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Obtaining the model from Sagemaker model registry.\n",
    "package_group = \"ChurnPackageGroup\"\n",
    "model_packages = client.list_model_packages(ModelPackageGroupName = package_group)\n",
    "\n",
    "\n",
    "latest_package = model_packages[\"ModelPackageSummaryList\"][0]\n",
    "latest_package_arn = latest_package[\"ModelPackageArn\"]\n",
    "\n",
    "print(latest_package)\n",
    "print(latest_package_arn)\n",
    "\n",
    "\n",
    "latest_package_details = client.describe_model_package(ModelPackageName=latest_package_arn)\n",
    "\n",
    "from sagemaker.model import Model\n",
    "inference_model = Model(image_uri = latest_package_details['InferenceSpecification']['Containers'][0]['Image'], \n",
    "                        entry_point='SageMaker_Pipeline_Component_Codes/Scoring/inference.py', \n",
    "                        model_data = latest_package_details['InferenceSpecification']['Containers'][0][\"ModelDataUrl\"], \n",
    "                        role = role,\n",
    "                        sagemaker_session = sagemaker_session\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=inference_instance_type,\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"Get-Model\",\n",
    "    model=inference_model,\n",
    "    inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0168eded",
   "metadata": {},
   "source": [
    "### Making inference step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=inference_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=pipeline_output_path,\n",
    "    base_transform_job_name = \"Churn-Transformation\"\n",
    ")\n",
    "\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"Inference\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                          # data_type = \"text/csv\"\n",
    "                         )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b92cc",
   "metadata": {},
   "source": [
    "### Building the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"Churn-Scoring\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        batch_data,\n",
    "        pipeline_output_path,\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        inference_instance_type\n",
    "    ],\n",
    "    steps=[step_process, step_create_model, step_transform]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ecadb1",
   "metadata": {},
   "source": [
    "### Uploading the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
