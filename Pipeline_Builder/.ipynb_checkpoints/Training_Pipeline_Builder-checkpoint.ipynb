{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\n",
      "<sagemaker.session.Session object at 0x7f53b0152210>\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "# sagemaker_session = sagemaker.session.Session(default_bucket = pipeline_output_bucket)\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = \"arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\"\n",
    "\n",
    "print(role)\n",
    "print(sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking configuration parameter values from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the configurations from config.json file.\n",
    "import json\n",
    "with open(\"config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase = build_parameters[\"usecase\"]\n",
    "\n",
    "## Handling the input location\n",
    "# Default input location\n",
    "# pipeline_input_bucket = f\"{usecase}-input-bucket-{region}\" \n",
    "pipeline_input_bucket = build_parameters[\"input_bucket\"]\n",
    "\n",
    "# Making the output location runtime parameter\n",
    "# pipeline_input_bucket = ParameterString(name = \"PipelineInputBucket\", default_value = pipeline_s3_input_bucket) \n",
    "\n",
    "\n",
    "# Default location for the datasets\n",
    "input_train_data_uri = f\"s3://{pipeline_input_bucket}/churn-bigml-80.csv\"\n",
    "input_test_data_uri = f\"s3://{pipeline_input_bucket}/churn-bigml-20.csv\"\n",
    "input_evaluation_data_uri = f\"s3://{pipeline_input_bucket}/churn-bigml-20.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# Parametrizing Data paths\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "train_data = ParameterString(name=\"TrainData\", default_value = input_train_data_uri)\n",
    "test_data = ParameterString(name=\"TestData\", default_value = input_test_data_uri)\n",
    "evaluation_data = ParameterString(name=\"EvaluationData\", default_value = input_evaluation_data_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling the output location\n",
    "# Default output location\n",
    "# pipeline_s3_output_bucket = f\"{usecase}-output-bucket-{region}\" \n",
    "# pipeline_s3_output_bucket = build_parameters[\"output_bucket\"]\n",
    "pipeline_output_bucket = build_parameters[\"output_bucket\"] \n",
    "\n",
    "# Making the output location runtime parameter\n",
    "# pipeline_output_bucket = ParameterString(name = \"PipelineOutputBucket\", default_value = pipeline_s3_output_bucket) \n",
    "sagemaker_session.default_bucket = pipeline_output_bucket\n",
    "\n",
    "# Creating the output bucket if it is not already present\n",
    "s3 = boto3.client('s3')\n",
    "buckets = [dictionary[\"Name\"] for dictionary in s3.list_buckets()['Buckets']]\n",
    "if pipeline_output_bucket not in buckets:\n",
    "    location = {'LocationConstraint': region}\n",
    "    response = s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration = location)\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "pipeline_start_time = strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "from sagemaker.workflow import functions\n",
    "\n",
    "# These variables were written thinking that output path can be taken as parameter, yes it can be done,\n",
    "# but not all the pipeline steps accepts pipeline parameter as input, so we had to pick the output path from config\n",
    "# file instead of as parameter\n",
    "# processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"ProcessingOutput\"])\n",
    "# evaluation_processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"EvaluationProcessingOutput\"])\n",
    "# # hptune_training_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"HPTuneTrainingOutput\"])\n",
    "# hptune_training_output_path = f\"s3://{pipeline_s3_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/HPTuneTrainingOutput\"\n",
    "# evaluation_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"EvaluationOutput\"])\n",
    "\n",
    "\n",
    "processing_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/ProcessingOutput\"\n",
    "evaluation_processing_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/EvaluationProcessingOutput\"\n",
    "# hptune_training_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"HPTuneTrainingOutput\"])\n",
    "hptune_training_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/HPTuneTrainingOutput\"\n",
    "evaluation_output_path = f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/{pipeline_start_time}/EvaluationOutput\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining runtime parameters related to preprocessing\n",
    "# Defining the default location for the parameters\n",
    "input_feature_selection_file_uri = f\"s3://{pipeline_input_bucket}/Feature_Selection.csv\"\n",
    "# preprocessing_code_location_uri = f\"s3://{pipeline_input_bucket}/codes/Training_Preprocessing.py\"\n",
    "\n",
    "# Basic feature selection file path\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = input_feature_selection_file_uri)\n",
    "# preprocessing_code_location = ParameterString(name = \"ProcessingCodeLocation\", default_value = preprocessing_code_location_uri)\n",
    "\n",
    "# Defining machine types\n",
    "# processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "# processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=\"ml.m5.4xlarge\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# framework_version = \"0.23-1\"\n",
    "framework_version = build_parameters[\"sklearn_processor_framework_version\"]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "#     framework_version = processing_framework_sklearn_version,\n",
    "    framework_version = framework_version,\n",
    "    instance_type = build_parameters[\"processing_instance_type\"],\n",
    "    instance_count= build_parameters[\"processing_instance_count\"],\n",
    "    base_job_name = f\"{usecase}-preprocessing\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, TuningStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name = \"preprocessing_full_data\",\n",
    "    description = \"Data preprocessing and splitting into train and test set\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source = train_data, destination=\"/opt/ml/processing/input/data\"),  \n",
    "        ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        # ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = f\"{processing_output_path}/data/\"),\n",
    "        ProcessingOutput(output_name = \"train\", source=\"/opt/ml/processing/train\", destination = sagemaker.workflow.functions.Join(on='/', values = [processing_output_path, \"data\"])),\n",
    "        # ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination = f\"{processing_output_path}/data/\"),\n",
    "        # ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination = f\"{processing_output_path}/data/\"),\n",
    "        ProcessingOutput(output_name = \"test\", source=\"/opt/ml/processing/test\", destination = sagemaker.workflow.functions.Join(on='/', values = [processing_output_path, \"data\"])),\n",
    "        # ProcessingOutput(output_name=\"logs\", source=\"/opt/ml/processing/logss\", destination = f\"{processing_output_path}/logs/\")\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", destination = sagemaker.workflow.functions.Join(on='/', values = [processing_output_path, \"logs\"])),\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Training/Training_Preprocessing.py\",\n",
    "    code = f\"s3://{pipeline_input_bucket}/codes/{build_parameters['processing_code_file_name']}\",\n",
    "    job_arguments = [\"--train_data_location\", \"/opt/ml/processing/input/data\", \"--feature_selection_file_location\", \n",
    "                     \"/opt/ml/processing/input/feature_selection\", \"--target_column\", \"Churn\",\n",
    "                     \"--preprocessed_train_data_location\", \"/opt/ml/processing/train\", \"--preprocessed_test_data_location\", \n",
    "                     \"/opt/ml/processing/test\", \"--log_location\", \"/opt/ml/processing/logss\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor_evaluation = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=build_parameters[\"processing_instance_type\"],\n",
    "    instance_count=build_parameters[\"processing_instance_count\"],\n",
    "    base_job_name=f\"{usecase}-preprocessing-validation\",\n",
    "    role=role\n",
    ")\n",
    "\n",
    "step_process_evaluation = ProcessingStep(\n",
    "    name=\"preprocessing_validation_data\",\n",
    "    # processor=sklearn_processor_evaluation,\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=evaluation_data, destination=\"/opt/ml/processing/input/data\"), \n",
    "        ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = sagemaker.workflow.functions.Join(on='/', values = [evaluation_processing_output_path, \"data\"])),\n",
    "        ProcessingOutput(output_name=\"logs\", source=\"/opt/ml/processing/logss\", destination = sagemaker.workflow.functions.Join(on='/', values = [evaluation_processing_output_path, \"logs\"]))\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Training/Training_Preprocessing.py\",\n",
    "    code = f\"s3://{pipeline_input_bucket}/codes/{build_parameters['processing_code_file_name']}\",\n",
    "    depends_on = [step_process],\n",
    "    job_arguments = [\"--train_data_location\", \"/opt/ml/processing/input/data\", \"--feature_selection_file_location\", \n",
    "                     \"/opt/ml/processing/input/feature_selection\", \"--target_column\", \"Churn\", \"--stop_split\", \"Y\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_objective_metric_name = build_parameters[\"objective_metric\"]\n",
    "objective_metric_name = ParameterString(name = \"ObjectiveMetric\", default_value = default_objective_metric_name)\n",
    "metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"accuracy:([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "sklearn_image_uri = image_uris.retrieve(framework='sklearn', region=region, version='0.23-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter, HyperparameterTuner, WarmStartConfig, WarmStartTypes\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "duplicate_objective_metric_name = ParameterString(name = \"ObjectiveMetric\", default_value = default_objective_metric_name)\n",
    "\n",
    "n_models = build_parameters[\"number_of_models\"]\n",
    "tuning_steps = []\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    if model_details[\"model_type\"] == 'sklearn_model':\n",
    "        estimator = SKLearn(source_dir = f\"s3://{pipeline_input_bucket}/codes/{model_details['model_name']}.tar.gz\", \n",
    "                            entry_point = model_details[\"entry_point\"], \n",
    "                            dependencies = model_details[\"dependencies\"], \n",
    "                            instance_type = model_details[\"instance_type\"], \n",
    "                            framework_version = '0.20.0', \n",
    "                            output_path = f\"{hptune_training_output_path}/{model_details['model_name']}\",\n",
    "                            image_uri = sklearn_image_uri, role = role\n",
    "                            )\n",
    "        \n",
    "        hyperparameters = model_details[\"hyperparameters\"].keys()\n",
    "        hyperparameter_ranges = {}\n",
    "        for hyperparameter in hyperparameters:\n",
    "            if model_details[\"hyperparameters\"][hyperparameter][\"type\"] == \"categorical\":\n",
    "                hyperparameter_ranges[hyperparameter] = CategoricalParameter(model_details[\"hyperparameters\"][hyperparameter][\"values\"])\n",
    "            elif model_details[\"hyperparameters\"][hyperparameter][\"type\"] == \"integer\":\n",
    "                hyperparameter_ranges[hyperparameter] = IntegerParameter(min_value = model_details[\"hyperparameters\"][hyperparameter][\"min_value\"],\n",
    "                                                                         max_value = model_details[\"hyperparameters\"][hyperparameter][\"max_value\"])\n",
    "        \n",
    "        hyperparameter_ranges[\"objective_metric\"] = CategoricalParameter([objective_metric_name, \"anything\"])\n",
    "        tuner = HyperparameterTuner(\n",
    "            estimator,\n",
    "            objective_metric_name,\n",
    "            hyperparameter_ranges,\n",
    "            metric_definitions,\n",
    "            max_jobs=1,\n",
    "            max_parallel_jobs=1,\n",
    "            strategy = model_details[\"tuning_strategy\"],\n",
    "            base_tuning_job_name = model_details[\"model_name\"],\n",
    "            # base_tuning_job_name=f\"Decision_Tree_{strftime('%Y%m%d-%H-%M-%S', gmtime())}\"\n",
    "            )\n",
    "        # print(f\"HPTuning-{model_details['model_name']}\")\n",
    "        step_tuning = TuningStep(\n",
    "            name = f\"hptuning-{model_details['model_name']}\",\n",
    "            tuner = tuner,\n",
    "            inputs={\n",
    "                \"train\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"test\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        tuning_steps.append(step_tuning)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the best model from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=build_parameters[\"evaluation_instance_type\"],\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "create_best_model_steps = []\n",
    "entry_point='SageMaker_Pipeline_Component_Codes/Training/Evaluation.py',\n",
    "for i in range(n_models):\n",
    "    tuning_step_best_model = Model(image_uri = tuning_steps[i].tuner.estimator.image_uri, \n",
    "                                   source_dir = f\"s3://{pipeline_input_bucket}/codes/evaluation.tar.gz\",\n",
    "                                   # source_dir = build_parameters[\"single_model_evluation_source_dir\"],\n",
    "                                   entry_point = build_parameters[\"single_model_evluation_entry_point\"],\n",
    "                                   model_data = sagemaker.workflow.functions.Join(on='/', values=[hptune_training_output_path, tuning_steps[i].name[9:], tuning_steps[i].properties.BestTrainingJob.TrainingJobName, \"output/model.tar.gz\"]), \n",
    "                                   role = role,\n",
    "                                   sagemaker_session = sagemaker_session\n",
    "                                  )\n",
    "    \n",
    "    step_create_best_model = CreateModelStep(\n",
    "        name = f\"Getting-Best-{tuning_steps[i].name[9:]}-Model\",\n",
    "        model = tuning_step_best_model,\n",
    "        inputs = inputs\n",
    "    )\n",
    "    \n",
    "    create_best_model_steps.append(step_create_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the best models from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_steps = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    transformer_dt = Transformer(\n",
    "        model_name = create_best_model_steps[i].properties.ModelName,\n",
    "        instance_type = build_parameters[\"evaluation_instance_type\"],\n",
    "        instance_count=1,\n",
    "        output_path=f\"{hptune_training_output_path}/{tuning_steps[i].name[9:]}/BestModel\",\n",
    "        base_transform_job_name = f\"{usecase}-evaluation-{tuning_steps[i].name[9:]}\",\n",
    "        env = {\"MODELS3LOCATION\":create_best_model_steps[i].properties.PrimaryContainer.ModelDataUrl, \n",
    "               \"MODELNAME\":build_parameters[\"model_specifications\"][f\"model{i}\"][\"model_name\"]}\n",
    "    )\n",
    "    evaluation_step = TransformStep(\n",
    "        name=f\"Evaluating-Best-{tuning_steps[i].name[9:]}-Model\",\n",
    "        transformer=transformer_dt,\n",
    "        inputs=TransformInput(data=step_process_evaluation.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri, \n",
    "                              # data_type = \"text/csv\"\n",
    "                             )\n",
    "    )\n",
    "    evaluation_steps.append(evaluation_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the best model based on model performance metric on evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(n_models):\n",
    "    inputs.append(ProcessingInput(sagemaker.workflow.functions.Join(on='/', values=[evaluation_steps[i].properties.TransformOutput.S3OutputPath, \"evaluation.csv.out\"]), destination=f\"/opt/ml/processing/input/model{i}\"))\n",
    "# inputs = inputs + [ProcessingInput(sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", \"Model_Performance_Metrics.csv\"]), destination=f\"/opt/ml/processing/metrics\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "property_file = PropertyFile(\n",
    "    name=\"property_file\",\n",
    "    output_name=\"property_file\",\n",
    "    path=\"property_file.json\"\n",
    ")\n",
    "\n",
    "step_get_best_model = ProcessingStep(\n",
    "    name = \"Getting-Best-Model\",\n",
    "    description = \"Picking the best model based on the metric value calculated using evaluation data\",\n",
    "    processor = sklearn_processor,\n",
    "    inputs=inputs,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"final_model\", source = \"/opt/ml/processing/final_model\", destination = evaluation_output_path),\n",
    "        ProcessingOutput(output_name=\"logs\", source = \"/opt/ml/processing/logs\", destination = evaluation_output_path),\n",
    "        ProcessingOutput(output_name=\"Metrics\", source = \"/opt/ml/processing/metrics_folder\", \n",
    "                         destination = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\"])\n",
    "                        ),\n",
    "                         # f\"s3://{pipeline_output_bucket}/Training_Pipeline_Output/\")\n",
    "        ProcessingOutput(output_name=\"property_file\", source = \"/opt/ml/processing/evaluation\", destination = evaluation_output_path)\n",
    "    ],\n",
    "    # code=\"SageMaker_Pipeline_Component_Codes/Training/Final_Model_Selection.py\",\n",
    "    code = f\"s3://{pipeline_input_bucket}/codes/{build_parameters['get_best_model_code_file_name']}\",\n",
    "    # depends_on = [step_dt_evaluation, step_lr_evaluation],\n",
    "    depends_on = evaluation_steps,\n",
    "    job_arguments = [\"--input_folder\", \"/opt/ml/processing/input\", \"--final_model_location\", \"/opt/ml/processing/final_model\", \n",
    "                     \"--logs_location\", \"/opt/ml/processing/logs\", \n",
    "                     # \"--model_metric_input_location\", \"/opt/ml/processing/metrics\", \n",
    "                     \"--model_metric_input_location\", sagemaker.workflow.functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", \"Model_Performance_Metrics.csv\"]),\n",
    "                     \"--model_metric_output_location\", \"/opt/ml/processing/metrics_folder\", \"--objective_metric\", objective_metric_name, \n",
    "                     \"--property_file_location\", \"/opt/ml/processing/evaluation\"],\n",
    "    property_files=[property_file]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register best model in SageMaker model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "register_best_model_steps = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    if model_details[\"model_type\"] == 'sklearn_model':\n",
    "        estimator = SKLearn(entry_point = \"\", \n",
    "                            \n",
    "                            instance_type = model_details[\"instance_type\"],\n",
    "                            framework_version = '0.20.0', \n",
    "                            image_uri = sklearn_image_uri,\n",
    "                            \n",
    "                            role = role\n",
    "                            )\n",
    "        register_best_model_step = RegisterModel(name=f\"RegisterBest{model_details['model_name']}Model\", \n",
    "                              estimator = estimator, \n",
    "                              # model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_path),\n",
    "                              model_data=sagemaker.workflow.functions.Join(on='/', values=[step_get_best_model.properties.ProcessingOutputConfig.Outputs[\"final_model\"].S3Output.S3Uri, \"model.tar.gz\"]),\n",
    "                              content_types=[\"text/csv\"],\n",
    "                              response_types=[\"text/csv\"],\n",
    "                              inference_instances=[model_details[\"instance_type\"]],\n",
    "                              transform_instances=[model_details[\"instance_type\"]],\n",
    "                              model_package_group_name = build_parameters[\"model_package_group_name\"],\n",
    "                              image_uri = sklearn_image_uri,\n",
    "                              # approval_status=\"Approved\",\n",
    "                              role=role,\n",
    "                              depends_on = []\n",
    "                             )\n",
    "        register_best_model_steps.append(register_best_model_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Endpoint with latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_endpoint_steps = []\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    model_name = model_details[\"model_name\"]\n",
    "    \n",
    "    step_update_endpoint = ProcessingStep(\n",
    "        name = f\"Updating-Endpoint-with-{model_name}\",\n",
    "        processor = sklearn_processor,\n",
    "        inputs=inputs,\n",
    "    \n",
    "        # code=\"SageMaker_Pipeline_Component_Codes/Training/Final_Model_Selection.py\",\n",
    "        code = f\"s3://{pipeline_input_bucket}/codes/{build_parameters['endpoint_updater_code_location'].split('/')[-1]}\",\n",
    "        # depends_on = [step_dt_evaluation, step_lr_evaluation],\n",
    "        # depends_on = [register_best_model_steps[i]],\n",
    "        job_arguments = [\"--pipeline_output_bucket\", pipeline_output_bucket, \"--role\", role, \n",
    "                         \"--pipeline_input_bucket\", pipeline_input_bucket, \n",
    "                         # \"--model_metric_input_location\", \"/opt/ml/processing/metrics\", \n",
    "                         \"--package_group\", build_parameters[\"model_package_group_name\"], \n",
    "                         \"--target_column\", build_parameters[\"target_column\"], \n",
    "                         \"--endpoint_name\", build_parameters[\"endpoint_name\"],\n",
    "                         \"--inference_code_name\", build_parameters[\"scoring_code_location\"].split('/')[-1]\n",
    "                        ],\n",
    "        property_files=[property_file]\n",
    "    )\n",
    "    update_endpoint_steps.append(step_update_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "condition_steps = []\n",
    "for i in range(n_models):\n",
    "    model_details = build_parameters[\"model_specifications\"][f\"model{i}\"]\n",
    "    condition_equal = ConditionEquals(left = JsonGet(step_name=step_get_best_model.name, \n",
    "                                                   property_file=property_file, \n",
    "                                                   json_path=\"best_model_name\"),\n",
    "                                      right = model_details[\"model_name\"]\n",
    "                                     )\n",
    "    step_cond = ConditionStep(\n",
    "        name=f\"Is-{model_details['model_name']}-Best-Model\",\n",
    "        conditions=[condition_equal],\n",
    "        if_steps = [register_best_model_steps[i], update_endpoint_steps[i]],\n",
    "        )\n",
    "    condition_steps.append(step_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arranging the steps inside pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"{usecase}-training\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        train_data,\n",
    "        test_data,\n",
    "        evaluation_data,\n",
    "        feature_selection_file,\n",
    "        pipeline_output_bucket,\n",
    "        #model_given,\n",
    "        #model_path,\n",
    "#         pipeline_output_path,\n",
    "        # processing_instance_count,\n",
    "        objective_metric_name,\n",
    "        # processing_code_location,\n",
    "        #training_instance_type,\n",
    "        #evaluation_instance_type\n",
    "    ],\n",
    "#     steps=[step_process, step_process_evaluation, step_tuning_dt, step_tuning_lr, step_create_best_dt_model, step_cond],\n",
    "#     steps=[step_process_evaluation, step_process, step_tuning_dt, step_tuning_lr, step_create_best_dt_model, step_create_best_lr_model, step_dt_evaluation, step_lr_evaluation, step_cond]\n",
    "#     steps=[step_process, step_tuning_dt, step_process_evaluation, step_tuning_lr, step_create_best_dt_model, step_create_best_lr_model, step_dt_evaluation, step_lr_evaluation, step_get_best_model, step_register_best_model]\n",
    "#     steps = [step_cond]\n",
    "    steps = [step_process] + tuning_steps + [step_process_evaluation] + create_best_model_steps + evaluation_steps + [step_get_best_model] + condition_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ParameterString is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c8e5744c9f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_arn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# execution = pipeline.start()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mupsert\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_arn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallelism_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_arn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 old_tags = self.sagemaker_session.sagemaker_client.list_tags(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, role_arn, description, parallelism_config)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_arn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallelism_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36m_create_args\u001b[0;34m(self, role_arn, description, parallelism_config)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mcreate_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mpipeline_definition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         kwargs = dict(\n\u001b[1;32m    140\u001b[0m             \u001b[0mPipelineName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mdefinition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefinition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;34m\"\"\"Converts a request structure to string representation for workflow service calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolate_step_collection_name_in_depends_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Steps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         request_dict[\"PipelineExperimentConfig\"] = interpolate(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mto_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_experiment_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;34m\"Steps\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist_to_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         }\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/utilities.py\u001b[0m in \u001b[0;36mlist_to_request\u001b[0;34m(entities)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEntity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mrequest_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStepCollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mrequest_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py\u001b[0m in \u001b[0;36mto_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRequestType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;34m\"\"\"Updates the dictionary with cache configuration.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py\u001b[0m in \u001b[0;36mto_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRequestType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;34m\"\"\"Gets the request structure for `ConfigurableRetryStep`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mstep_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_policies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstep_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RetryPolicies\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_retry_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_policies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py\u001b[0m in \u001b[0;36mto_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;34m\"Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;34m\"Arguments\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         }\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepends_on\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py\u001b[0m in \u001b[0;36marguments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             \u001b[0mtuner_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TuningJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tuner_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tuning_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtuner_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_get_tuner_args\u001b[0;34m(cls, tuner, inputs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m             \u001b[0mtuning_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective_metric_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_metric_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m         \u001b[0mparameter_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameter_ranges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparameter_ranges\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0mtuning_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parameter_ranges\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter_ranges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mhyperparameter_ranges\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         return self._prepare_parameter_ranges_for_tuning(\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparameter_ranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         )\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_prepare_parameter_ranges_for_tuning\u001b[0;34m(cls, parameter_ranges, estimator)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFramework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     ):\n\u001b[0;32m-> 1100\u001b[0;31m                         \u001b[0mtuning_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_json_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                         \u001b[0mtuning_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tuning_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/parameter.py\u001b[0m in \u001b[0;36mas_json_range\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mhyperparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mJSON\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/parameter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mhyperparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mJSON\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ParameterString is not JSON serializable"
     ]
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
