{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50eb784b",
   "metadata": {},
   "source": [
    "# Importing Libraries and Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ecb9e",
   "metadata": {},
   "source": [
    "https://github.com/aws/amazon-sagemaker-examples/issues/1207\n",
    "\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49344ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "# Taking pipeline building configurations from config.json.\n",
    "# These are only for building and will not be available at \n",
    "# the runtime of the pipeline.\n",
    "with open(\"config.json\") as file:\n",
    "    build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec806df",
   "metadata": {},
   "source": [
    "# Setting Default Bucket and getting region and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31420ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn-output-bucket-us-east-1\n",
      "churn-output-bucket-us-east-1\n",
      "arn:aws:iam::852619674999:role/service-role/AmazonSageMaker-ExecutionRole-20220427T124311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Setting default bucket\n",
    "# Method 1\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "pipeline_session = PipelineSession(default_bucket = build_parameters[\"output_bucket\"])\n",
    "sagemaker_session = sagemaker.Session(default_bucket = build_parameters[\"output_bucket\"])\n",
    "\n",
    "# Method 2\n",
    "pipeline_session.default_bucket = build_parameters[\"output_bucket\"]\n",
    "sagemaker_session.default_bucket = build_parameters[\"output_bucket\"]\n",
    "\n",
    "# Method 3\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# bucket = \"sagemaker-output-bucket-us-east1\"   \n",
    "\n",
    "print(sagemaker_session.default_bucket)\n",
    "print(pipeline_session.default_bucket)\n",
    "\n",
    "\n",
    "## Getting region and role\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ad58d",
   "metadata": {},
   "source": [
    "# Input Data Location Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12eef6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Default location for the datasets\n",
    "train_data_uri = build_parameters[\"train_data\"]\n",
    "test_data_uri = build_parameters[\"test_data\"]\n",
    "evaluation_data_uri = build_parameters[\"evaluation_data\"]\n",
    "feature_selection_file_uri = build_parameters[\"feature_selection\"]\n",
    "\n",
    "\n",
    "# Parametrizing Data paths\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "train_data = ParameterString(name=\"TrainData\", default_value = train_data_uri)\n",
    "test_data = ParameterString(name=\"TestData\", default_value = test_data_uri)\n",
    "evaluation_data = ParameterString(name=\"EvaluationData\", default_value = evaluation_data_uri)\n",
    "feature_selection_file = ParameterString(name = \"FeatureSelectionFile\", default_value = feature_selection_file_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea73f7b",
   "metadata": {},
   "source": [
    "#### Handling Output Locations\n",
    "See this link to learn more about pipeline execution variables: https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.execution_variables.ExecutionVariables\n",
    "pipeline_start_time is a execution vairable, so to create processig_output_path and inference_output_path we had to use sagemaker.workflow.functions.Join and we could not use Python f-strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c52228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline_output_bucket = build_parameters[\"output_bucket\"]\n",
    "\n",
    "pipeline_start_time = sagemaker.workflow.execution_variables.ExecutionVariables.START_DATETIME\n",
    "\n",
    "from sagemaker.workflow import functions\n",
    "train_processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"TrainProcessingOutput\"])\n",
    "validation_processing_output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"ValidationProcessingOutput\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb815ac",
   "metadata": {},
   "source": [
    "# Step 1: Preprocessing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f4e77",
   "metadata": {},
   "source": [
    "#### 1.1 Loading preprocessing config.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b145a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_preprocessing_path = os.path.join(\"Pipeline_Component_Codes\",\"Training\",\"1_Preprocessing\")\n",
    "with open(os.path.join(local_preprocessing_path, \"config.json\")) as file:\n",
    "    processing_build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19e822",
   "metadata": {},
   "source": [
    "#### 1.2 Making parameter for processing machine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6a7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=processing_build_parameters[\"machine_type\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0c092",
   "metadata": {},
   "source": [
    "#### 1.3 Building the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db093a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if processing_build_parameters[\"processing_type\"] == \"sklearn\":\n",
    "    from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "    processor = SKLearnProcessor(\n",
    "        framework_version = processing_build_parameters[\"framework_version\"],\n",
    "        instance_type = processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )\n",
    "elif processing_build_parameters[\"processing_type\"] == \"custom\":\n",
    "    from sagemaker.processor import Processor\n",
    "    processor = Processor(\n",
    "        image_uri = processing_build_parameters[\"image_uri\"],\n",
    "        instance_type = processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ff7fb",
   "metadata": {},
   "source": [
    "#### 1.4 Building preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2190cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name = \"preprocessing_full_data\",\n",
    "    description = \"Data preprocessing and splitting into train and test set\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source = train_data, destination=\"/opt/ml/processing/input/data\"),  \n",
    "        ProcessingInput(source=feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        # Train\n",
    "        ProcessingOutput(output_name = \"train\", source=\"/opt/ml/processing/train\", \n",
    "                         destination = train_processing_output_path\n",
    "                        ),\n",
    "        # Test\n",
    "        ProcessingOutput(output_name = \"test\", source=\"/opt/ml/processing/test\", \n",
    "                         destination = train_processing_output_path\n",
    "                        ),\n",
    "        # Logs\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "                         destination = train_processing_output_path\n",
    "                        ),\n",
    "    ],\n",
    "    code=os.path.join(local_preprocessing_path, processing_build_parameters[\"entry_point\"]),\n",
    "    job_arguments = [\"--train_data_location\", \"/opt/ml/processing/input/data\", \n",
    "                     \"--feature_selection_file_location\", \"/opt/ml/processing/input/feature_selection/Feature_Selection.csv\", \n",
    "                     \"--target_column\", \"Churn\",\n",
    "                     \"--preprocessed_train_data_location\", \"/opt/ml/processing/train\", \n",
    "                     \"--preprocessed_test_data_location\", \"/opt/ml/processing/test\", \n",
    "                     \"--log_location\", \"/opt/ml/processing/logss\"\n",
    "                    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01502d39",
   "metadata": {},
   "source": [
    "# Step 2: Processing Evaluation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f0102",
   "metadata": {},
   "source": [
    "#### 2.1 Loading preprocessing config.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ddaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_val_processing_path = os.path.join(\"Pipeline_Component_Codes\",\"Training\",\"11_Validation_Processing\")\n",
    "with open(os.path.join(local_val_processing_path, \"config.json\")) as file:\n",
    "    val_processing_build_parameters = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3886e",
   "metadata": {},
   "source": [
    "#### 2.2 Making parameter for processing machine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49bb90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_processing_instance_type = ParameterString(\n",
    "    name=\"ValProcessingInstanceType\",\n",
    "    default_value=val_processing_build_parameters[\"machine_type\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d06cd",
   "metadata": {},
   "source": [
    "#### 2.3 Building the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d307fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if val_processing_build_parameters[\"processing_type\"] == \"sklearn\":\n",
    "    from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "    processor = SKLearnProcessor(\n",
    "        framework_version = val_processing_build_parameters[\"framework_version\"],\n",
    "        instance_type = val_processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = val_processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )\n",
    "elif processing_build_parameters[\"processing_type\"] == \"custom\":\n",
    "    from sagemaker.processor import Processor\n",
    "    processor = Processor(\n",
    "        image_uri = val_processing_build_parameters[\"image_uri\"],\n",
    "        instance_type = val_processing_build_parameters[\"machine_type\"],\n",
    "        instance_count = val_processing_build_parameters[\"machine_count\"],\n",
    "        base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "        role=role\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7267ca",
   "metadata": {},
   "source": [
    "#### 2.4 Building preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69accd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "step_val_process = ProcessingStep(\n",
    "    name = \"preprocessing_validation_data\",\n",
    "    description = \"Validation data preprocessing.\",\n",
    "    processor=processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source = evaluation_data, destination=\"/opt/ml/processing/input/data\"),  \n",
    "        ProcessingInput(source = feature_selection_file, destination=\"/opt/ml/processing/input/feature_selection\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        # Evaluation data\n",
    "        ProcessingOutput(output_name = \"evaluation\", source=\"/opt/ml/processing/test\", \n",
    "                         destination = validation_processing_output_path\n",
    "                        ),\n",
    "        # Logs\n",
    "        ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "                         destination = validation_processing_output_path\n",
    "                        ),\n",
    "    ],\n",
    "    code=os.path.join(local_val_processing_path, val_processing_build_parameters[\"entry_point\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3a46e",
   "metadata": {},
   "source": [
    "# Step 3: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3134418",
   "metadata": {},
   "source": [
    "#### 3.1 Getting models from Local Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd98bf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Decision_Tree', 'Logistic_Regression']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "local_models_path = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"2_Models_HPTune\")\n",
    "models = []\n",
    "for directory in os.listdir(local_models_path):\n",
    "    if '.' not in directory: # Avoiding .ipynb_checkpoints\n",
    "        models.append(directory)\n",
    "\n",
    "models = models[:-1]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6a268",
   "metadata": {},
   "source": [
    "#### 3.2 Reading config.json Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386fa9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = {}\n",
    "for model in models:\n",
    "    with open(os.path.join(local_models_path, model, \"config.json\")) as file:\n",
    "        model_build_parameters = json.load(file)\n",
    "    model_details[model] = model_build_parameters\n",
    "\n",
    "# print(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c018c",
   "metadata": {},
   "source": [
    "#### 3.2 Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "670ed605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine types\n",
    "training_instances = []\n",
    "for model in models:\n",
    "    training_instance_type = ParameterString(\n",
    "        name=f\"{model}_InstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    "    )\n",
    "    training_instances.append(training_instance_type)\n",
    "\n",
    "# Objective metric\n",
    "# objective_metric_name = ParameterString(name = \"ObjectiveMetric\", default_value = build_parameters[\"objective_metric\"])\n",
    "# metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"accuracy:([0-9\\\\.]+)\"}]\n",
    "\n",
    "objective_metric_name = \"validation:accuracy\"\n",
    "metric_definitions = [{'Name': \"validation:accuracy\", 'Regex': \"accuracy:([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e8f2d",
   "metadata": {},
   "source": [
    "#### 3.3 Creating the Estimators on which Tuning Will Happen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc300d",
   "metadata": {},
   "source": [
    "Sagemaker provides us docker conatiners for all the popular algorithms like they have scikit learn image for all the Scikit learn models, they have XGBoost image and they also have deep learning images as well. Here for the demo purpose we have used only three models, Logistic Regression, Decision Tree and XGBoost. So our need was not to build our own image. If any other Python library is needed we can mention those in **requirements.txt** file. We do not have to do anything more, pipeline will automatically install those in respective containers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4788777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "from sagemaker.workflow import functions\n",
    "\n",
    "\n",
    "\n",
    "tuning_steps = []\n",
    "index = -1\n",
    "for model in models:\n",
    "    index = index + 1\n",
    "    current_model_details = model_details[model]\n",
    "    \n",
    "    output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"HPTuningOutputs\", model])\n",
    "    \n",
    "    # Creating the Estimators on which Tuning Will Happen\n",
    "    if current_model_details['model_type'] == 'sklearn_model':\n",
    "        estimator = SKLearn(\n",
    "                            source_dir = os.path.join(local_models_path, model),\n",
    "                            entry_point = current_model_details[\"entry_point\"], \n",
    "                            instance_type = training_instances[index], \n",
    "                            instance_count = 1,\n",
    "                            framework_version = current_model_details[\"framework_version\"], \n",
    "                            role = role,\n",
    "                            output_path = output_path\n",
    "                            )\n",
    "    elif current_model_details['model_type'] == 'xgboost_model':\n",
    "        estimator = XGBoost(\n",
    "                            source_dir = os.path.join(local_models_path, model),\n",
    "                            entry_point = current_model_details[\"entry_point\"],\n",
    "                            instance_type = training_instances[index],\n",
    "                            instance_count = 1,\n",
    "                            framework_version = current_model_details[\"framework_version\"],\n",
    "                            role=role,\n",
    "                            output_path = output_path\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    # Getting the hyperparameters\n",
    "    hyperparameters = current_model_details[\"hyperparameters\"]\n",
    "    \n",
    "    hyperparameter_ranges = {}\n",
    "    for hyperparameter in hyperparameters:\n",
    "        if hyperparameters[hyperparameter][\"type\"] == \"continuous\":\n",
    "            hyperparameter_ranges[hyperparameter] = ContinuousParameter(min_value = hyperparameters[hyperparameter][\"min_value\"],\n",
    "                                                                        max_value = hyperparameters[hyperparameter][\"max_value\"],\n",
    "                                                                        scaling_type = hyperparameters[hyperparameter][\"scaling_type\"])\n",
    "        elif hyperparameters[hyperparameter][\"type\"] == \"categorical\":\n",
    "            hyperparameter_ranges[hyperparameter] = CategoricalParameter(hyperparameters[hyperparameter][\"values\"])\n",
    "        elif hyperparameters[hyperparameter][\"type\"] == \"integer\":\n",
    "            hyperparameter_ranges[hyperparameter] = IntegerParameter(min_value = hyperparameters[hyperparameter][\"min_value\"],\n",
    "                                                                     max_value = hyperparameters[hyperparameter][\"max_value\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Making the hyperparameter tuner\n",
    "    tuner = HyperparameterTuner(\n",
    "        estimator = estimator,\n",
    "        objective_metric_name = objective_metric_name,\n",
    "        hyperparameter_ranges = hyperparameter_ranges,\n",
    "        metric_definitions = metric_definitions,\n",
    "        max_jobs=1,\n",
    "        max_parallel_jobs=1,\n",
    "        strategy = current_model_details[\"tuning_strategy\"],\n",
    "        base_tuning_job_name = current_model_details[\"model_name\"]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Building the tuning step\n",
    "    step_tuning = TuningStep(\n",
    "        name = f\"hptuning_{current_model_details['model_name']}\",\n",
    "        tuner = tuner,\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            ),\n",
    "            \"test\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    tuning_steps.append(step_tuning)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f3955",
   "metadata": {},
   "source": [
    "# Step: 4: Getting the best model from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffcec9",
   "metadata": {},
   "source": [
    "Follow this link to get example of how to write lambda step https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-pipelines/tabular/lambda-step/sagemaker-pipelines-lambda-step.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc723c7",
   "metadata": {},
   "source": [
    "#### 4.1 Building the Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a52b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "\n",
    "func = Lambda(\n",
    "    function_name = \"get_best_model_from_hptune_job\",\n",
    "    execution_role_arn=\"arn:aws:iam::852619674999:role/role_given_to_lambda\",\n",
    "#     execution_role_arn = role,\n",
    "#     execution_role_arn = lambda_role,\n",
    "    script = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"3_HPTune_Best_Model\", \"main.py\"),\n",
    "    handler=\"main.main\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c1530",
   "metadata": {},
   "source": [
    "#### 4.2 Building the Lambdastep\n",
    "See this link to get the idea on how tuning step name is being fetched (tuning_steps[i].properties.HyperParameterTuningJobName): https://boto3.amazonaws.com/v1/documentation/api/1.9.46/reference/services/sagemaker.html#SageMaker.Client.describe_hyper_parameter_tuning_job \n",
    "In the same way other properties can also be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91105ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaOutput, LambdaStep, LambdaOutputTypeEnum\n",
    "\n",
    "best_model_steps = []\n",
    "for i in range(len(models)):\n",
    "    # Building the outputs\n",
    "    output_param_1 = LambdaOutput(output_name=f\"best_model_location\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_2 = LambdaOutput(output_name=f\"best_metric_value\", output_type=LambdaOutputTypeEnum.String)\n",
    "    output_param_3 = LambdaOutput(output_name=f\"best_model\", output_type=LambdaOutputTypeEnum.String)\n",
    "    \n",
    "    # Building the Lambdastep\n",
    "    step_deploy_lambda = LambdaStep(\n",
    "        name=f\"get_best_{models[i]}_model\",\n",
    "        lambda_func=func,\n",
    "        inputs={\n",
    "            \"tuning_job_name\": tuning_steps[i].properties.HyperParameterTuningJobName\n",
    "        },\n",
    "#         outputs=[output_param_1, output_param_2],\n",
    "        outputs=[output_param_1, output_param_2, output_param_3]\n",
    "    )\n",
    "    \n",
    "    best_model_steps.append(step_deploy_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06430a9",
   "metadata": {},
   "source": [
    "# Step 5: Evaluating the best models from each hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc260b22",
   "metadata": {},
   "source": [
    "#### Building Property Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ee4888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_reports = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    evaluation_report = PropertyFile(\n",
    "        name = f\"evaluating_best_{models[i]}_model\",\n",
    "        output_name = \"evaluation\",\n",
    "        path = \"evaluation.json\"\n",
    "    )\n",
    "    \n",
    "    evaluation_reports.append(evaluation_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5678860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "evaluation_steps = []\n",
    "for i in range(len(models)):\n",
    "    \n",
    "    # Building evaluator\n",
    "    current_model_details = model_details[models[i]]\n",
    "    \n",
    "    if current_model_details['model_type'] == 'sklearn_model':\n",
    "        evaluator = SKLearnProcessor(\n",
    "        framework_version = current_model_details[\"framework_version\"],\n",
    "        instance_type = training_instances[i],\n",
    "        instance_count = 1,\n",
    "        role=role\n",
    "        )\n",
    "    elif current_model_details['model_type'] != 'sklearn_model':\n",
    "        # Logic is not complete\n",
    "        evaluator = Processor(\n",
    "            image_uri = processing_build_parameters[\"image_uri\"],\n",
    "            instance_type = processing_build_parameters[\"machine_type\"],\n",
    "            instance_count = processing_build_parameters[\"machine_count\"],\n",
    "            base_job_name = f\"{build_parameters['usecase']}-preprocessing\",\n",
    "            role=role\n",
    "        )\n",
    "    \n",
    "    output_path = functions.Join(on='/', values=[\"s3:/\", pipeline_output_bucket, \"Training_Pipeline_Output\", pipeline_start_time, \"EvaluationOutputs\", models[i]])\n",
    "    \n",
    "    # Building the evaluation step\n",
    "    step_evaluation = ProcessingStep(\n",
    "        name = f\"evaluating_best_{models[i]}_model\",\n",
    "        description = f\"Evaluating best {models[i]} model.\",\n",
    "        processor = evaluator,\n",
    "        inputs=[\n",
    "            ProcessingInput(source = step_val_process.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri, destination=\"/opt/ml/processing/input/data\"),\n",
    "            ProcessingInput(source = best_model_steps[i].properties.Outputs[\"best_model_location\"], destination=\"/opt/ml/processing/input/model\"),  \n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\",\n",
    "                             source=\"/opt/ml/processing/test\",\n",
    "                             destination = output_path\n",
    "                            ),\n",
    "            # Logs\n",
    "            ProcessingOutput(output_name = \"logs\", source=\"/opt/ml/processing/logss\", \n",
    "                             destination = output_path\n",
    "                            )\n",
    "        ],\n",
    "        code = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"4_Model_Evaluation\", \"main.py\"),\n",
    "        property_files=[evaluation_reports[i]],\n",
    "        job_arguments = [\"--objective_metric\", build_parameters[\"objective_metric\"], \n",
    "                         \"--model_name\", models[i],\n",
    "                         \"--best_model_location\", best_model_steps[i].properties.Outputs[\"best_model_location\"]\n",
    "                        ]\n",
    "    )\n",
    "    \n",
    "    evaluation_steps.append(step_evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6750a",
   "metadata": {},
   "source": [
    "# Step 6: Getting the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09f202",
   "metadata": {},
   "source": [
    "#### Building the Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a8c61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get_final_model_func = Lambda(\n",
    "#     function_name = \"get_final_model\",\n",
    "#     execution_role_arn=\"arn:aws:iam::852619674999:role/role_given_to_lambda\",\n",
    "# #     execution_role_arn = role,\n",
    "# #     execution_role_arn = lambda_role,\n",
    "#     script = os.path.join(\"Pipeline_Component_Codes\", \"Training\", \"3_HPTune_Best_Model\", \"main.py\"),\n",
    "#     handler=\"main.main\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ed1d1",
   "metadata": {},
   "source": [
    "#### Building the Lambdastep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9975c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# output_param_1 = LambdaOutput(output_name=f\"final_model_location\", output_type=LambdaOutputTypeEnum.String)\n",
    "# output_param_2 = LambdaOutput(output_name=f\"final_metric_value\", output_type=LambdaOutputTypeEnum.String)\n",
    "# output_param_3 = LambdaOutput(output_name=f\"final_model\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=f\"best_model_location\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=f\"best_metric_value\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=f\"best_model\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "\n",
    "lambda_inputs = {'n':len(models)}\n",
    "for i in range(len(models)):\n",
    "    best_model_location = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_model_location\")\n",
    "    metrics = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_metric_value\")\n",
    "    model = JsonGet(step_name = evaluation_steps[i].name, property_file = evaluation_reports[i], json_path=\"best_model\")\n",
    "    \n",
    "    lambda_inputs[f\"best_model_location{i}\"] = best_model_location\n",
    "    lambda_inputs[f\"metrics{i}\"] = metrics\n",
    "    lambda_inputs[f\"model{i}\"] = model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "step_final_model = LambdaStep(\n",
    "    name=f\"get_final_model\",\n",
    "    lambda_func=func,\n",
    "    inputs = lambda_inputs,\n",
    "    outputs=[output_param_1, output_param_2, output_param_3]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937fb627",
   "metadata": {},
   "source": [
    "# Step 8: Register best model in SageMaker model registry\n",
    "Yes, we have to build step 8 before step 7. Step 7 will be a condition step and to define a condition step we have to first define what is the step which will be executed, if the condition in condition step is true and which is the step that will be if the condition is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ae526d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker import image_uris\n",
    "\n",
    "register_best_model_steps = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    current_model_details = model_details[models[i]]\n",
    "    \n",
    "    # Creating the estimator\n",
    "    if current_model_details['model_type'] == 'sklearn_model':\n",
    "        estimator = SKLearn(entry_point = \"\", \n",
    "                            instance_type = training_instances[i], \n",
    "                            framework_version = current_model_details[\"framework_version\"], \n",
    "                            role = role,\n",
    "                            )\n",
    "        image_uri = image_uris.retrieve(framework='sklearn', region=region, version=current_model_details[\"framework_version\"])\n",
    "    elif current_model_details['model_type'] == 'xgboost_model':\n",
    "        # This logic is not complete\n",
    "        estimator = XGBoost(entry_point = \"\",\n",
    "                            instance_type = training_instances[i],\n",
    "                            framework_version = current_model_details[\"framework_version\"],\n",
    "                            role=role,\n",
    "                            )\n",
    "        image_uri = image_uris.retrieve(framework='xgboost', region=region, version=current_model_details[\"framework_version\"])\n",
    "    \n",
    "    \n",
    "    register_best_model_step = RegisterModel(name=f\"RegisterBest{models[i]}Model\",\n",
    "                                             estimator = estimator, \n",
    "                                             # model_data=step_final_model.properties.Outputs[\"final_model_location\"],\n",
    "                                             model_data=step_final_model.properties.Outputs[\"best_model_location\"],\n",
    "                                             content_types=[\"text/csv\"],\n",
    "                                             response_types=[\"text/csv\"],\n",
    "                                             inference_instances=[current_model_details[\"instance_type\"]],\n",
    "                                             transform_instances=[current_model_details[\"instance_type\"]],\n",
    "                                             model_package_group_name = build_parameters[\"model_package_group_name\"],\n",
    "                                             image_uri = image_uri,\n",
    "                                             # approval_status=\"Approved\",\n",
    "                                             role=role,\n",
    "                                             depends_on = []\n",
    "                                            )\n",
    "    register_best_model_steps.append(register_best_model_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd50cb9",
   "metadata": {},
   "source": [
    "# Step 7: Checking which Model is the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e69da92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "condition_steps = []\n",
    "for i in range(len(models)):\n",
    "    condition_equal = ConditionEquals(\n",
    "        # left = step_final_model.properties.Outputs[\"final_model\"],\n",
    "        left = step_final_model.properties.Outputs[\"best_model\"],\n",
    "                                      right = models[i]\n",
    "                                     )\n",
    "    step_cond = ConditionStep(\n",
    "        name=f\"Is-{models[i]}-Best-Model\",\n",
    "        conditions=[condition_equal],\n",
    "        if_steps = [register_best_model_steps[i]],\n",
    "        )\n",
    "    condition_steps.append(step_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969d182",
   "metadata": {},
   "source": [
    "### Model Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if build_parameters[\"given_model_type\"] == \"sklearn\":\n",
    "#     estimator = SKLearn(entry_point = \"\", \n",
    "                        \n",
    "#                         instance_type = build_parameters[\"scoring_instance_type\"],\n",
    "#                         framework_version = '0.20.0', \n",
    "#                         image_uri = sklearn_image_uri,\n",
    "                        \n",
    "#                         role = role\n",
    "#                         )\n",
    "    \n",
    "#     register_given_model_step = RegisterModel(name=f\"RegisterGivenModel\", \n",
    "#                                              estimator = estimator, \n",
    "#                                              # model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_path),\n",
    "#                                              model_data=build_parameters[\"given_model_path\"],\n",
    "#                                              content_types=[\"text/csv\"],\n",
    "#                                              response_types=[\"text/csv\"],\n",
    "#                                              inference_instances=[build_parameters[\"scoring_instance_type\"]],\n",
    "#                                              transform_instances=[build_parameters[\"scoring_instance_type\"]],\n",
    "#                                              model_package_group_name = build_parameters[\"model_package_group_name\"],\n",
    "#                                              image_uri = sklearn_image_uri,\n",
    "#                                              approval_status=\"Approved\",\n",
    "#                                              role=role,\n",
    "#                                              depends_on = []\n",
    "#                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_given_condition = ConditionEquals(left = build_parameters[\"model_given\"],\n",
    "#                                         right = \"No\"\n",
    "#                                        )\n",
    "# step_model_given_cond = ConditionStep(\n",
    "#     name=f\"Is-Model-Given\",\n",
    "#     conditions=[model_given_condition],\n",
    "#     # if_steps = [register_given_model_step],\n",
    "#     if_steps = [step_process] + tuning_steps + [step_process_evaluation] + create_best_model_steps + evaluation_steps + [step_get_best_model] + condition_steps,\n",
    "#     else_steps = [register_given_model_step]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8745051",
   "metadata": {},
   "source": [
    "# Building the Pipeline\n",
    "#### Arranging the steps inside pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cec6e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"{build_parameters['usecase']}-training\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[train_data, test_data, evaluation_data, feature_selection_file, \n",
    "                processing_instance_type] + training_instances + [objective_metric_name],\n",
    "    steps = [step_process, step_val_process] + tuning_steps + best_model_steps + evaluation_steps + [step_final_model] + condition_steps,\n",
    "    sagemaker_session = pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f578e",
   "metadata": {},
   "source": [
    "#### Uploading the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d694fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:852619674999:pipeline/churn-training',\n",
       " 'ResponseMetadata': {'RequestId': '40e7860f-889f-444f-9c4c-6300a3223a1f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '40e7860f-889f-444f-9c4c-6300a3223a1f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Fri, 19 May 2023 12:48:06 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37659dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a30fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b2d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
